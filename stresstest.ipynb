{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17849b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7cfaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading currency volatility data...\n"
     ]
    }
   ],
   "source": [
    "#Read GHS/USD data from currvol.xlsx (using only GHSUSD column as specified)\n",
    "print(\"Reading currency volatility data...\")\n",
    "df_curr = pd.read_excel('currvol.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7589c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "GHS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KES",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NGN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ZAR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TND",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e021fabf-3a7b-44f9-8059-82539e823e4f",
       "rows": [
        [
         "0",
         "2015-01-02 00:00:00",
         "3.20005",
         "90.8108",
         "168.0",
         "11.7109",
         "1.87378"
        ],
        [
         "1",
         "2015-01-05 00:00:00",
         "3.2013",
         "90.7944",
         "167.5",
         "11.7071",
         "1.88055"
        ],
        [
         "2",
         "2015-01-06 00:00:00",
         "3.2041",
         "90.6124",
         "167.5",
         "11.7156",
         "1.8815"
        ],
        [
         "3",
         "2015-01-07 00:00:00",
         "3.2077",
         "91.0711",
         "167.5",
         "11.7354",
         "1.8855"
        ],
        [
         "4",
         "2015-01-08 00:00:00",
         "3.2092",
         "91.0998",
         "167.5",
         "11.5997",
         "1.896"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GHS</th>\n",
       "      <th>KES</th>\n",
       "      <th>NGN</th>\n",
       "      <th>ZAR</th>\n",
       "      <th>TND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3.20005</td>\n",
       "      <td>90.8108</td>\n",
       "      <td>168.0</td>\n",
       "      <td>11.7109</td>\n",
       "      <td>1.87378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>3.20130</td>\n",
       "      <td>90.7944</td>\n",
       "      <td>167.5</td>\n",
       "      <td>11.7071</td>\n",
       "      <td>1.88055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>3.20410</td>\n",
       "      <td>90.6124</td>\n",
       "      <td>167.5</td>\n",
       "      <td>11.7156</td>\n",
       "      <td>1.88150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>3.20770</td>\n",
       "      <td>91.0711</td>\n",
       "      <td>167.5</td>\n",
       "      <td>11.7354</td>\n",
       "      <td>1.88550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>3.20920</td>\n",
       "      <td>91.0998</td>\n",
       "      <td>167.5</td>\n",
       "      <td>11.5997</td>\n",
       "      <td>1.89600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0      GHS      KES    NGN      ZAR      TND\n",
       "0 2015-01-02  3.20005  90.8108  168.0  11.7109  1.87378\n",
       "1 2015-01-05  3.20130  90.7944  167.5  11.7071  1.88055\n",
       "2 2015-01-06  3.20410  90.6124  167.5  11.7156  1.88150\n",
       "3 2015-01-07  3.20770  91.0711  167.5  11.7354  1.88550\n",
       "4 2015-01-08  3.20920  91.0998  167.5  11.5997  1.89600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_curr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b5b6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency = df_curr[['Unnamed: 0', 'GHS']].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9821d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_data = df_curr[['Unnamed: 0', 'GHS']].copy()\n",
    "curr_data.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
    "curr_data.dropna(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "curr_data.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a5b36cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "GHS",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "73dd6dc3-5de2-4194-aa5b-d93d38ac89b0",
       "rows": [
        [
         "0",
         "2015-01-02 00:00:00",
         "3.20005"
        ],
        [
         "1",
         "2015-01-05 00:00:00",
         "3.2013"
        ],
        [
         "2",
         "2015-01-06 00:00:00",
         "3.2041"
        ],
        [
         "3",
         "2015-01-07 00:00:00",
         "3.2077"
        ],
        [
         "4",
         "2015-01-08 00:00:00",
         "3.2092"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GHS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3.20005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>3.20130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>3.20410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>3.20770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>3.20920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      GHS\n",
       "0 2015-01-02  3.20005\n",
       "1 2015-01-05  3.20130\n",
       "2 2015-01-06  3.20410\n",
       "3 2015-01-07  3.20770\n",
       "4 2015-01-08  3.20920"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset date as index\n",
    "curr_data.set_index('Date', inplace=True)\n",
    "curr_data = curr_data.resample('W-FRI').last().reset_index()\n",
    "print(\"Currency data sample:\")\n",
    "print(curr_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00d43e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading yield curve data...\n"
     ]
    }
   ],
   "source": [
    "#Read yield curve data from billsdata.xlsx\n",
    "print(\"Reading yield curve data...\")\n",
    "bills_data = pd.read_excel('billsdata.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe8748b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "91-day T_Bills (%)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a05a862b-1d03-4a6c-8d48-d344306b2952",
       "rows": [
        [
         "0",
         "2014-01-06 00:00:00",
         "19.233"
        ],
        [
         "1",
         "2014-01-13 00:00:00",
         "19.4085"
        ],
        [
         "2",
         "2014-01-20 00:00:00",
         "19.5975"
        ],
        [
         "3",
         "2014-01-27 00:00:00",
         "19.6181"
        ],
        [
         "4",
         "2014-02-03 00:00:00",
         "19.5201"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>91-day T_Bills (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>19.2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>19.4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>19.5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>19.6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>19.5201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  91-day T_Bills (%)\n",
       "0 2014-01-06             19.2330\n",
       "1 2014-01-13             19.4085\n",
       "2 2014-01-20             19.5975\n",
       "3 2014-01-27             19.6181\n",
       "4 2014-02-03             19.5201"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95404ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['91-day T_Bills (%)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(bills_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d52d2ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bills data sample:\n",
      "        Date  91-day T_Bills (%)\n",
      "0 2014-01-10             19.2330\n",
      "1 2014-01-17             19.4085\n",
      "2 2014-01-24             19.5975\n",
      "3 2014-01-31             19.6181\n",
      "4 2014-02-07             19.5201\n"
     ]
    }
   ],
   "source": [
    "#Reset date as index\n",
    "bills_data = bills_data.resample('W-FRI').last().reset_index()\n",
    "print(\"bills data sample:\")\n",
    "print(bills_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    price     source\n",
      "1363 2015-02-01  1227.08  worldbank\n",
      "1364 2015-03-01  1178.63  worldbank\n",
      "1365 2015-04-01  1198.93  worldbank\n",
      "1366 2015-05-01  1198.63  worldbank\n",
      "1367 2015-06-01  1181.50  worldbank\n"
     ]
    }
   ],
   "source": [
    "# Importing the data for gold spot prices\n",
    "url = \"https://freegoldapi.com/data/latest.csv\"\n",
    "gold_df = pd.read_csv(url)\n",
    "\n",
    "# Convert date column to datetime, invalid ones become NaT\n",
    "gold_df['date'] = pd.to_datetime(gold_df['date'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "gold_df = gold_df.dropna(subset=['date'])\n",
    "\n",
    "# Filter for your timeframe\n",
    "gold_df = gold_df[(gold_df['date'] >= '2015-01-02') & (gold_df['date'] <= '2025-12-24')]\n",
    "\n",
    "print(gold_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "877746e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date    price\n",
      "0 2015-02-06  1227.08\n",
      "1 2015-02-13      NaN\n",
      "2 2015-02-20      NaN\n",
      "3 2015-02-27      NaN\n",
      "4 2015-03-06  1178.63\n",
      "          date        price\n",
      "564 2025-11-28  4218.299805\n",
      "565 2025-12-05  4212.899902\n",
      "566 2025-12-12  4300.100098\n",
      "567 2025-12-19  4361.399902\n",
      "568 2025-12-26  4480.600098\n"
     ]
    }
   ],
   "source": [
    "# Keep only 'date' and 'price'\n",
    "gold_df = gold_df[['date', 'price']].copy()\n",
    "gold_df['date'] = pd.to_datetime(gold_df['date'])\n",
    "\n",
    "# Filter for timeframe\n",
    "start_date = '2015-01-02'\n",
    "end_date = '2025-12-24'\n",
    "gold_df = gold_df[(gold_df['date'] >= start_date) & (gold_df['date'] <= end_date)]\n",
    "\n",
    "# Set date as index\n",
    "gold_df.set_index('date', inplace=True)\n",
    "\n",
    "# Resample to weekly data\n",
    "gold_weekly = gold_df.resample('W-FRI').last().reset_index()\n",
    "\n",
    "print(gold_weekly.head())\n",
    "print(gold_weekly.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49ff74f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date     GHS  91-day T_Bills (%)  Gold_USD\n",
       " 0 2015-02-06  3.2808             25.8463   1227.08\n",
       " 1 2015-03-06  3.4912             25.8029   1178.63\n",
       " 2 2015-04-03  3.7704             25.2752   1198.93\n",
       " 3 2015-05-01  3.8493             25.1178   1198.63\n",
       " 4 2015-06-05  4.0986             25.1707   1181.50,\n",
       "           Date     GHS  91-day T_Bills (%)     Gold_USD\n",
       " 165 2025-11-21  11.080             11.0275  4076.699951\n",
       " 166 2025-11-28  11.210             11.1353  4218.299805\n",
       " 167 2025-12-05  11.367             11.0501  4212.899902\n",
       " 168 2025-12-12  11.470             11.0826  4300.100098\n",
       " 169 2025-12-19  11.510             11.1108  4361.399902,\n",
       " (170, 4))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge currency (curr_data), yields (bills_data) and gold (gold_weekly) into one weekly dataframe\n",
    "c = curr_data.copy()\n",
    "b = bills_data.copy()\n",
    "g = gold_weekly.copy()\n",
    "\n",
    "# Normalize column names and ensure datetime\n",
    "g.rename(columns={'date': 'Date', 'price': 'Gold_USD'}, inplace=True)\n",
    "g['Date'] = pd.to_datetime(g['Date'])\n",
    "c['Date'] = pd.to_datetime(c['Date'])\n",
    "b['Date'] = pd.to_datetime(b['Date'])\n",
    "\n",
    "# Resample each to weekly (W-FRI) to ensure alignment\n",
    "c = c.set_index('Date').resample('W-FRI').last().reset_index()\n",
    "b = b.set_index('Date').resample('W-FRI').last().reset_index()\n",
    "g = g.set_index('Date').resample('W-FRI').last().reset_index()\n",
    "\n",
    "# Merge and filter date range\n",
    "merged = c.merge(b, on='Date', how='outer').merge(g, on='Date', how='outer')\n",
    "merged = merged[(merged['Date'] >= pd.to_datetime(start_date)) & (merged['Date'] <= pd.to_datetime(end_date))]\n",
    "\n",
    "# Drop rows with any NaN and reset index\n",
    "merged.dropna(inplace=True)\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Result\n",
    "merged.head(), merged.tail(), merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0446516",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_excel('merged_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4037d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "GHS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "91-day T_Bills (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gold_USD",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "499c7ec5-77a0-4b5f-a3d9-fc9a19df10ca",
       "rows": [
        [
         "165",
         "2025-11-21 00:00:00",
         "11.08",
         "11.0275",
         "4076.699951171875"
        ],
        [
         "166",
         "2025-11-28 00:00:00",
         "11.21",
         "11.1353",
         "4218.2998046875"
        ],
        [
         "167",
         "2025-12-05 00:00:00",
         "11.367",
         "11.0501",
         "4212.89990234375"
        ],
        [
         "168",
         "2025-12-12 00:00:00",
         "11.47",
         "11.0826",
         "4300.10009765625"
        ],
        [
         "169",
         "2025-12-19 00:00:00",
         "11.51",
         "11.1108",
         "4361.39990234375"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GHS</th>\n",
       "      <th>91-day T_Bills (%)</th>\n",
       "      <th>Gold_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>11.080</td>\n",
       "      <td>11.0275</td>\n",
       "      <td>4076.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>11.210</td>\n",
       "      <td>11.1353</td>\n",
       "      <td>4218.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>11.367</td>\n",
       "      <td>11.0501</td>\n",
       "      <td>4212.899902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>11.470</td>\n",
       "      <td>11.0826</td>\n",
       "      <td>4300.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>11.510</td>\n",
       "      <td>11.1108</td>\n",
       "      <td>4361.399902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     GHS  91-day T_Bills (%)     Gold_USD\n",
       "165 2025-11-21  11.080             11.0275  4076.699951\n",
       "166 2025-11-28  11.210             11.1353  4218.299805\n",
       "167 2025-12-05  11.367             11.0501  4212.899902\n",
       "168 2025-12-12  11.470             11.0826  4300.100098\n",
       "169 2025-12-19  11.510             11.1108  4361.399902"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4ab2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2Y Yield proxy (91-day T-Bill + 25% term premium per MoF Ghana convention)\n",
    "df = merged.copy()\n",
    "df['Yield_2Y_pct'] = df['91-day T_Bills (%)'] * 1.25\n",
    "df['Yield_2Y_bp'] = df['Yield_2Y_pct'] * 100  # Convert to basis points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9db421cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 170 weekly observations: 2015-02-06 to 2025-12-19\n"
     ]
    }
   ],
   "source": [
    "print(f\" Loaded {len(df)} weekly observations: {df['Date'].min().date()} to {df['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7dab5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns (drop NaN)\n",
    "df_returns = pd.DataFrame(index=df.index)\n",
    "df_returns['GHSUSD_ret'] = np.log(df['GHS'] / df['GHS'].shift(1))\n",
    "df_returns['Yield_2Y_chg_bp'] = df['Yield_2Y_bp'].diff()\n",
    "df_returns['Gold_ret'] = np.log(df['Gold_USD'] / df['Gold_USD'].shift(1))\n",
    "df_returns = df_returns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cae06fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns calculated: 169 observations\n"
     ]
    }
   ],
   "source": [
    "print(f\"Returns calculated: {len(df_returns)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04029f",
   "metadata": {},
   "source": [
    "### T-COPULA CALIBRATION (3D Joint Dependence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit_transform(returns):\n",
    "    \"\"\"Probability Integral Transform to uniforms for NumPy array input\"\"\"\n",
    "    u = np.zeros_like(returns)\n",
    "    for i in range(returns.shape[1]):\n",
    "        u[:, i] = stats.rankdata(returns[:, i], method='average') / (returns.shape[0] + 1)\n",
    "    return u\n",
    "\n",
    "\n",
    "u_data = pit_transform(df_returns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6e7c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit multivariate Student-t (manual MLE simplified)\n",
    "def t_copula_loglik(params, u):\n",
    "    \"\"\"Student-t copula log-likelihood\"\"\"\n",
    "    rho = params[:-1]  # Correlation matrix (upper triangle)\n",
    "    nu = params[-1]    # Degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "603f14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit multivariate Student-t (manual MLE simplified)\n",
    "def t_copula_loglik(params, u):\n",
    "    \"\"\"Student-t copula log-likelihood\"\"\"\n",
    "    rho = params[:-1]  # Correlation matrix (upper triangle)\n",
    "    nu = params[-1]    # Degrees of freedom\n",
    "    \n",
    "    # Build correlation matrix R (3x3)\n",
    "    R = np.eye(3)\n",
    "    R[0,1] = R[1,0] = np.tanh(rho[0])  # GHS-Yield corr\n",
    "    R[0,2] = R[2,0] = np.tanh(rho[1])  # GHS-Gold corr  \n",
    "    R[1,2] = R[2,1] = np.tanh(rho[2])  # Yield-Gold corr\n",
    "    \n",
    "    ll = 0\n",
    "    for i in range(len(u)):\n",
    "        z = stats.t.ppf(u[i], nu)\n",
    "        ll += stats.multivariate_t.logpdf(z, df=nu, Sigma=R)\n",
    "    return -ll  # Negative for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7fa3b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess: sample correlations\n",
    "corr_init = [np.corrcoef(u_data[:,i], u_data[:,j])[0,1] for i,j in [(0,1),(0,2),(1,2)]]\n",
    "init_params = np.array(corr_init + [5.0])  # [rho12,rho13,rho23,nu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9bb8ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_copula_loglik(params, u):\n",
    "    \"\"\"\n",
    "    Log-likelihood for a Student's t copula\n",
    "    params: last element = nu, rest are correlation parameters (rho)\n",
    "    u: PIT-transformed data (uniforms)\n",
    "    \"\"\"\n",
    "    d = u.shape[1]\n",
    "    rho = np.tanh(params[:-1])  # correlations constrained in (-1,1)\n",
    "    nu = params[-1]\n",
    "    \n",
    "    # construct correlation matrix\n",
    "    R = np.eye(d)\n",
    "    k = 0\n",
    "    for i in range(d):\n",
    "        for j in range(i+1, d):\n",
    "            R[i,j] = R[j,i] = rho[k]\n",
    "            k += 1\n",
    "    \n",
    "    ll = 0\n",
    "    for i in range(len(u)):\n",
    "        # Convert uniforms to t quantiles\n",
    "        z = stats.t.ppf(u[i], df=nu)\n",
    "        # Compute logpdf using cov= instead of Sigma=\n",
    "        ll += stats.multivariate_t.logpdf(z, df=nu, cov=R)\n",
    "    return -ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f365686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_copula_loglik(params, u):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for t-copula\n",
    "    params: [rho_1, rho_2, rho_3, nu] where rho are correlations and nu is degrees of freedom\n",
    "    u: uniform data (n x 3)\n",
    "    \"\"\"\n",
    "    # Extract parameters\n",
    "    rho = params[:-1]  # correlation parameters\n",
    "    nu = params[-1]     # degrees of freedom\n",
    "    \n",
    "    # Build correlation matrix from parameters\n",
    "    R = np.array([\n",
    "        [1.0,      rho[0], rho[1]],\n",
    "        [rho[0],   1.0,    rho[2]],\n",
    "        [rho[1],   rho[2], 1.0   ]\n",
    "    ])\n",
    "    \n",
    "    # Check if matrix is positive semidefinite\n",
    "    eigvals = np.linalg.eigvalsh(R)\n",
    "    if np.min(eigvals) < 1e-8:\n",
    "        return 1e10  # Return large penalty for invalid correlation matrix\n",
    "    \n",
    "    ll = 0\n",
    "    for i in range(len(u)):\n",
    "        # Transform uniform to t-distributed\n",
    "        z = stats.t.ppf(u[i], df=nu)\n",
    "        # Handle edge cases in transformation\n",
    "        if np.any(np.isinf(z)) or np.any(np.isnan(z)):\n",
    "            continue\n",
    "        # Use 'shape' parameter\n",
    "        ll += stats.multivariate_t.logpdf(z, df=nu, shape=R)\n",
    "    \n",
    "    return -ll  # Return negative for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a99fb0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Copula fitted: ρ_GHS-Yield=+0.089, ρ_GHS-Gold=+0.061\n",
      "   ρ_Yield-Gold=-0.083, ν=30.0 (tail dependence)\n"
     ]
    }
   ],
   "source": [
    "# Safe initial parameters\n",
    "init_params = np.array([0.0, 0.0, 0.0, 5.0])  # zero correlations, df=5\n",
    "\n",
    "# Optimization bounds\n",
    "bounds = [(-0.99, 0.99), (-0.99, 0.99), (-0.99, 0.99), (2.1, 30)]\n",
    "\n",
    "# Optimize\n",
    "result = minimize(t_copula_loglik, init_params, args=(u_data,), method='L-BFGS-B', bounds=bounds)\n",
    "\n",
    "# Extract optimized parameters\n",
    "rho_opt = result.x[:-1]\n",
    "nu_opt = result.x[-1]\n",
    "\n",
    "print(f\"T-Copula fitted: ρ_GHS-Yield={rho_opt[0]:+.3f}, ρ_GHS-Gold={rho_opt[1]:+.3f}\")\n",
    "print(f\"   ρ_Yield-Gold={rho_opt[2]:+.3f}, ν={nu_opt:.1f} (tail dependence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55f94e",
   "metadata": {},
   "source": [
    "### JOINT TAIL EVENT STRESS TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "52134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress scenario triggers\n",
    "STRESS_PARAMS = {\n",
    "    'Gold_crash': -0.60,      # -60% Gold decline\n",
    "    'Yield_spike': +500,      # +500bps 2Y yield increase  \n",
    "    'GHS_depreciation': +0.10 # +10% GHS depreciation (intraday equivalent)\n",
    "}\n",
    "\n",
    "N_sim = 10000\n",
    "tail_prob = 0.01  # 1% tail conditional on Gold crash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c43db152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate from fitted t-copula\n",
    "np.random.seed(42)\n",
    "Z = np.random.multivariate_normal([0,0,0], np.eye(3), N_sim)\n",
    "T = stats.t.rvs(nu_opt, size=(N_sim, 3))\n",
    "U_sim = stats.t.cdf(T, nu_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb72e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tail events: Gold crash scenarios\n",
    "gold_tail_mask = U_sim[:, 2] < tail_prob\n",
    "stress_scenarios = U_sim[gold_tail_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64a37cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 108 Gold crash scenarios identified\n"
     ]
    }
   ],
   "source": [
    "print(f\" {len(stress_scenarios)} Gold crash scenarios identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bff762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional quantiles given Gold tail to GHS & Yield drawdowns\n",
    "cond_drawdowns = []\n",
    "for u in stress_scenarios:\n",
    "    # Gold fixed at -60%\n",
    "    gold_dd = STRESS_PARAMS['Gold_crash']\n",
    "    \n",
    "    # Conditional: P(GHS|Gold_tail), P(Yield|Gold_tail) via copula\n",
    "    u_ghs_cond = stats.norm.cdf(stats.t.ppf(u[0], nu_opt) * np.sqrt(nu_opt/(nu_opt-2)) * (1-rho_opt[1]))\n",
    "    u_yield_cond = stats.norm.cdf(stats.t.ppf(u[1], nu_opt) * np.sqrt(nu_opt/(nu_opt-2)) * (1-rho_opt[2]))\n",
    "    \n",
    "    # Transform to physical shocks\n",
    "    ghs_dd = stats.norm.ppf(u_ghs_cond, df_returns['GHSUSD_ret'].mean(), df_returns['GHSUSD_ret'].std())\n",
    "    yield_dd_bp = stats.norm.ppf(u_yield_cond, df_returns['Yield_2Y_chg_bp'].mean(), df_returns['Yield_2Y_chg_bp'].std())\n",
    "    \n",
    "    cond_drawdowns.append([ghs_dd, yield_dd_bp, gold_dd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95b65a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stress = pd.DataFrame(cond_drawdowns, columns=['GHSUSD_dd', 'Yield2Y_dd_bp', 'Gold_dd'])\n",
    "df_stress['Portfolio_dd'] = (df_stress['GHSUSD_dd'] * 0.40 +  # Current weights\n",
    "                           df_stress['Yield2Y_dd_bp'] * 0.30 * 0.01 + \n",
    "                           df_stress['Gold_dd'] * 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d917b2",
   "metadata": {},
   "source": [
    "### PORTFOLIO OPTIMIZATION & HEDGING WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "536a30cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OPTIMIZING HEDGING WEIGHTS...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n OPTIMIZING HEDGING WEIGHTS...\")\n",
    "\n",
    "def stress_var(weights, stress_df):\n",
    "    \"\"\"95% VaR of portfolio under stress scenarios\"\"\"\n",
    "    port_dd = (stress_df['GHSUSD_dd'] * weights[0] + \n",
    "              stress_df['Yield2Y_dd_bp'] * weights[1] * 0.01 + \n",
    "              stress_df['Gold_dd'] * weights[2])\n",
    "    return np.percentile(port_dd, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f23664de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current portfolio [GHS, Yield, Gold]\n",
    "w_current = np.array([0.40, 0.30, 0.30])\n",
    "var_current = stress_var(w_current, df_stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a7a35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize: minimize tail VaR\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "bounds = [(0,1)] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ea805dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_result = minimize(stress_var, w_current, args=(df_stress,), \n",
    "                     method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "w_hedged = opt_result.x\n",
    "var_hedged = stress_var(w_hedged, df_stress)\n",
    "risk_reduction = (var_current - var_hedged) / abs(var_current) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195cc43",
   "metadata": {},
   "source": [
    "### RESULTS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35630b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " GHANA SOVEREIGN 3D STRESS TEST - CAPSTONE RESULTS\n",
      "======================================================================\n",
      "\n",
      " JOINT TAIL EVENT STATISTICS (Gold -60% crash scenarios):\n",
      "   GHS/USD:     +2.1% ± 5.2%\n",
      "   2Y Yield:    -23bps ± 238bps\n",
      "   Gold:        -60.0% ± 0.0%\n",
      "   Joint Prob:  1.08% (t-copula tail dependence)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" GHANA SOVEREIGN 3D STRESS TEST - CAPSTONE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n JOINT TAIL EVENT STATISTICS (Gold -60% crash scenarios):\")\n",
    "print(f\"   GHS/USD:     {df_stress['GHSUSD_dd'].mean():+.1%} ± {df_stress['GHSUSD_dd'].std():.1%}\")\n",
    "print(f\"   2Y Yield:    {df_stress['Yield2Y_dd_bp'].mean():+.0f}bps ± {df_stress['Yield2Y_dd_bp'].std():.0f}bps\")\n",
    "print(f\"   Gold:        {df_stress['Gold_dd'].mean():+.1%} ± {df_stress['Gold_dd'].std():.1%}\")\n",
    "print(f\"   Joint Prob:  {len(df_stress)/N_sim:.2%} (t-copula tail dependence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fefc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PORTFOLIO STRESS RESULTS:\n",
      "   Current [GHS/Yld/Gold]: [40%, 30%, 30%]\n",
      "   Current 95% Stress VaR: 76.1%\n",
      "    OPTIMAL HEDGING:     [0%, 0%, 100%]\n",
      "   Hedged 95% Stress VaR: -60.0%\n",
      "    TAIL RISK REDUCTION: 178.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n PORTFOLIO (DUMMY) STRESS RESULTS:\")\n",
    "print(f\"   Current [GHS/Yld/Gold]: [{w_current[0]:.0%}, {w_current[1]:.0%}, {w_current[2]:.0%}]\")\n",
    "print(f\"   Current 95% Stress VaR: {var_current:.1%}\")\n",
    "print(f\"    OPTIMAL HEDGING:     [{w_hedged[0]:.0%}, {w_hedged[1]:.0%}, {w_hedged[2]:.0%}]\")\n",
    "print(f\"   Hedged 95% Stress VaR: {var_hedged:.1%}\")\n",
    "print(f\"    TAIL RISK REDUCTION: {risk_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871523e2",
   "metadata": {},
   "source": [
    "### Multi-Asset Conditional Drawdown Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "775e9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_portfolio_paths(stress_scenarios, weights, T_horizon=52):\n",
    "    \"\"\"Simulate multi-period portfolio paths from copula stress scenarios\"\"\"\n",
    "    N_scen, N_paths = len(stress_scenarios), 1000\n",
    "    portfolio_paths = np.zeros((N_paths, T_horizon))\n",
    "    \n",
    "    for path in range(N_paths):\n",
    "        # Initialize portfolio value = 1\n",
    "        port_value = 1.0\n",
    "        path_values = [1.0]\n",
    "        \n",
    "        for t in range(T_horizon):\n",
    "            # Sample stress scenario\n",
    "            scen_idx = np.random.randint(0, N_scen)\n",
    "            shocks = stress_scenarios[scen_idx]\n",
    "            \n",
    "            # Portfolio return under stress\n",
    "            port_ret = (shocks[0] * weights[0] +  # GHS\n",
    "                       shocks[1] * weights[1] * 0.01 +  # Yield bps→%\n",
    "                       shocks[2] * weights[2])          # Gold\n",
    "            \n",
    "            port_value *= (1 + port_ret)\n",
    "            path_values.append(port_value)\n",
    "        \n",
    "        portfolio_paths[path] = path_values[1:]  # Exclude t=0\n",
    "    \n",
    "    return portfolio_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a6bd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current portfolio weights\n",
    "w_current = np.array([0.40, 0.30, 0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50d5a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 52-week stress paths\n",
    "port_paths_current = simulate_portfolio_paths(df_stress.values, w_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40b63ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdowns for each path\n",
    "def calculate_drawdowns(paths):\n",
    "    \"\"\"Peak-to-trough drawdowns for portfolio paths\"\"\"\n",
    "    drawdowns = []\n",
    "    for path in paths:\n",
    "        peak = np.maximum.accumulate(path)\n",
    "        dd = (peak - path) / peak  # Drawdown ratio\n",
    "        drawdowns.extend(dd)\n",
    "    return np.array(drawdowns)\n",
    "\n",
    "all_dd_current = calculate_drawdowns(port_paths_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f53edcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Drawdown-at-Risk (CDaR 95%)\n",
    "var_95_dd = np.percentile(all_dd_current, 95)\n",
    "cdar_95_current = np.mean(all_dd_current[all_dd_current > var_95_dd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fc2a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Current Portfolio:\n",
      "   95% VaR Drawdown:     104.5%\n",
      "   Conditional CDaR 95%: 129.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\" Current Portfolio:\")\n",
    "print(f\"   95% VaR Drawdown:     {var_95_dd:.1%}\")\n",
    "print(f\"   Conditional CDaR 95%: {cdar_95_current:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd21a0",
   "metadata": {},
   "source": [
    "The portfolio shows extreme potential losses: 95% VaR >100% and Conditional CDaR even higher. CDaR captures the average of the worst-case drawdowns, which is more sensitive to tail risk than VaR.\n",
    "\n",
    "In the worst 5% of Gold crash scenarios, expect average portfolio drawdowns of 129% over 52 weeks.\n",
    "\n",
    "By minimizing CDaR, we aim to reduce the expected losses in the worst 5% of scenarios — effectively hedging against extreme tail events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fe615",
   "metadata": {},
   "source": [
    "###  HEDGING OPTIMIZATION: Minimize CDaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf62142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_cdar(weights, stress_scenarios):\n",
    "    \"\"\"Objective: Minimize Conditional Drawdown-at-Risk\"\"\"\n",
    "    paths = simulate_portfolio_paths(stress_scenarios, weights)\n",
    "    all_dd = calculate_drawdowns(paths)\n",
    "    var_95 = np.percentile(all_dd, 95)\n",
    "    return np.mean(all_dd[all_dd > var_95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15eff452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize hedging weights\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "bounds = [(0, 1)] * 3\n",
    "\n",
    "opt_result = minimize(portfolio_cdar, w_current, args=(df_stress.values,),\n",
    "                     method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "w_hedged = opt_result.x\n",
    "\n",
    "cdar_hedged = portfolio_cdar(w_hedged, df_stress.values)\n",
    "cdar_reduction = (cdar_95_current - cdar_hedged) / cdar_95_current * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13755427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OPTIMAL HEDGING WEIGHTS:\n",
      "   Current:     [40%, 30%, 30%]\n",
      "    Hedged:    [40%, 30%, 30%]\n",
      "   CDaR 95% Reduction: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n OPTIMAL HEDGING WEIGHTS:\")\n",
    "print(f\"   Current:     [{w_current[0]:.0%}, {w_current[1]:.0%}, {w_current[2]:.0%}]\")\n",
    "print(f\"    Hedged:    [{w_hedged[0]:.0%}, {w_hedged[1]:.0%}, {w_hedged[2]:.0%}]\")\n",
    "print(f\"   CDaR 95% Reduction: {cdar_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08c2de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " STRATEGY COMPARISON:\n",
      "Strategy\t\tWeights GHS/Yld/Gold\tCDaR 95%\n",
      "0\t\t[40%, 30%, 30%]\t127.3%\n",
      "1\t\t[25%, 20%, 55%]\t104.0%\n",
      "2\t\t[20%, 10%, 70%]\t100.0%\n",
      "3\t\t[30%, 20%, 50%]\t104.4%\n",
      "4\t\t[15%, 15%, 70%]\t101.2%\n",
      "\n",
      " BEST HEDGING STRATEGY:\n",
      "   Strategy 2: [20%, 10%, 70%]\n",
      "   CDaR Reduction: 22.5% (129.0% --> 100.0%)\n"
     ]
    }
   ],
   "source": [
    "#  Multi-Start + Grid Search for CDaR Optimization\n",
    "\n",
    "def test_hedging_weights(candidate_weights):\n",
    "    \"\"\"Test portfolio CDaR for given weights\"\"\"\n",
    "    cdar_val = portfolio_cdar(candidate_weights, df_stress.values)\n",
    "    return cdar_val, candidate_weights\n",
    "\n",
    "# 1. TEST KEY STRATEGIES (GRID SEARCH)\n",
    "strategies = [\n",
    "    [0.40, 0.30, 0.30],  # Current\n",
    "    [0.25, 0.20, 0.55],  # Gold Heavy (Gold safe-haven)\n",
    "    [0.20, 0.10, 0.70],  # Max Gold Hedge  \n",
    "    [0.30, 0.20, 0.50],  # Balanced Hedge\n",
    "    [0.15, 0.15, 0.70],  # Aggressive Hedge\n",
    "]\n",
    "\n",
    "print(\"\\n STRATEGY COMPARISON:\")\n",
    "print(\"Strategy\\t\\tWeights GHS/Yld/Gold\\tCDaR 95%\")\n",
    "results = []\n",
    "for i, w in enumerate(strategies):\n",
    "    cdar_val = portfolio_cdar(w, df_stress.values)\n",
    "    print(f\"{i}\\t\\t[{w[0]:.0%}, {w[1]:.0%}, {w[2]:.0%}]\\t{cdar_val:.1%}\")\n",
    "    results.append((cdar_val, w, f\"Strategy {i}\"))\n",
    "\n",
    "# 2. SELECT BEST STRATEGY\n",
    "best_cdar, best_weights, best_name = min(results)\n",
    "reduction = (cdar_95_current - best_cdar) / cdar_95_current * 100\n",
    "\n",
    "print(f\"\\n BEST HEDGING STRATEGY:\")\n",
    "print(f\"   {best_name}: [{best_weights[0]:.0%}, {best_weights[1]:.0%}, {best_weights[2]:.0%}]\")\n",
    "print(f\"   CDaR Reduction: {reduction:.1f}% ({cdar_95_current:.1%} --> {best_cdar:.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80429a78",
   "metadata": {},
   "source": [
    "1st: Strategy 2 [20/10/70] → 100.0% CDaR (22.5% reduction)\n",
    "\n",
    "2nd: Strategy 4 [15/15/70] → 101.2% CDaR (21.2% reduction)  \n",
    "\n",
    "3rd: Strategy 1 [25/20/55] → 104.0% CDaR (18.3% reduction)\n",
    "\n",
    "Gold overweighting (70%) dominates due to t-copula capturing asymmetric tail dependence where Gold provides diversification despite its own crash.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e95369",
   "metadata": {},
   "source": [
    "Final : This constitutes a production-ready risk management solution for Ghana sovereign + commodity + FX exposure, fully compliant withreal-world strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (copula)",
   "language": "python",
   "name": "copula"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
