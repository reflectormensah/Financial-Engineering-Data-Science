{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577c30de",
   "metadata": {},
   "source": [
    "### Installing and importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6259f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-autotime plotly --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23b2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pylance --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4213f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec155c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import openpyxl\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a74d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Dashboard\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe79e03",
   "metadata": {},
   "source": [
    "### DATA LOADING & INITIAL INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581a594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_inspect_data(filepath):\n",
    "    \"\"\"Load data and perform initial inspection\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA LOADING & INITIAL INSPECTION\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bfcee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data loaded successfully: 5,976 rows × 38 columns\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_excel(r\"C:\\Users\\reflectorm\\Downloads\\FRC_Readership.xlsx\")\n",
    "\n",
    "print(f\"\\n Data loaded successfully: {df.shape[0]:,} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44594694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset Overview:\n",
      "   Total Records: 5,976\n",
      "   Total Columns: 38\n",
      "   Memory Usage: 10.74 MB\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "print(\"\\n Dataset Overview:\")\n",
    "print(f\"   Total Records: {len(df):,}\")\n",
    "print(f\"   Total Columns: {len(df.columns)}\")\n",
    "print(f\"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "938bd99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date/time read",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Reader ID (FactSet)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Reader name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phone",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Parent Firm ID (FactSet)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Parent Firm name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Firm ID (FactSet)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Firm name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Address",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "State",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Reader Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Doc ID (contributor)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Doc ID (FactSet)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Readership Event ID (FactSet)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date/time published",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date/time received",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Report title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Primary issuer Ticker",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Primary issuer name",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Primary analyst code (contributor)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Primary analyst code (FactSet)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Primary analyst name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Number of pages in report",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Report Purpose",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Report Focus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Asset Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Asset Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Primary Industry Code (FactSet)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Primary Industry Name (FactSet)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Security Type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Discipline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Research Approach",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Periodicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Compilation Indicator",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1179394d-9e3d-4839-a765-b05af05bba2f",
       "rows": [
        [
         "0",
         "03-Jan-2019 12:29",
         "2019",
         "216246",
         "Srichandra, Andrew",
         "3125872920",
         "7199",
         "Driehaus Capital Management, LLC",
         "7199",
         "Driehaus Capital Management, LLC",
         "25 E. Erie  ",
         "Chicago",
         "IL",
         "US",
         "OUTNPCFENM72V64HXR3QPCUZLM6",
         "ba49c54a20f05455e01c58a54821f9fb",
         "1A7B791A0F7D11E9BD855A4B5E5A5609",
         "03-Jan-2019 12:27",
         "03-Jan-2019 12:27",
         "Databank Daily Market Review - (3rd January, 2019)",
         null,
         null,
         "16.0",
         "13292912.0",
         "Asante, Lawrencia",
         "5",
         null,
         "Index",
         "Equity",
         "Stock",
         "2225.0",
         "Agricultural Commodities/Milling",
         "Common",
         "Investment",
         "Fundamental",
         "Daily",
         "Africa",
         "Ghana",
         "Yes"
        ],
        [
         "1",
         "04-Jan-2019 12:33",
         "2019",
         "216246",
         "Srichandra, Andrew",
         "3125872920",
         "7199",
         "Driehaus Capital Management, LLC",
         "7199",
         "Driehaus Capital Management, LLC",
         "25 E. Erie  ",
         "Chicago",
         "IL",
         "US",
         "SBCLMJ6NEZ7SCR2RL3DA6IHSX46",
         "ed1911e5a0f1cc1ed6aa982507581d12",
         "E44489AC104611E98EE2BE3415941755",
         "04-Jan-2019 12:33",
         "04-Jan-2019 12:33",
         "Databank Weekly Market Review - (4th January, 2019)",
         null,
         null,
         "16.0",
         "13292912.0",
         "Asante, Lawrencia",
         "5",
         null,
         "Index",
         "Commodity",
         "Stock",
         "2225.0",
         "Agricultural Commodities/Milling",
         null,
         "Investment",
         "Fundamental",
         "Weekly",
         "Africa",
         "Ghana",
         "Yes"
        ],
        [
         "2",
         "08-Jan-2019 07:01",
         "2019",
         "833192",
         "Kelly, Georgia",
         "5184628355",
         "1437969",
         "BAML - GWIM 1100 Pennington",
         "1484773",
         "BAML Wealth Albany - WZ3291",
         "69 State St  ",
         "Albany",
         "NY",
         "US",
         "XJNGZ4WWNJOBZLRNREUKD5MXJI6",
         "a843aa3e16f7bea627fd712ad3dbee45",
         "1D74D8DC133D11E99017B9D35E5A5609",
         "08-Jan-2019 07:00",
         "08-Jan-2019 07:00",
         "DATABANK RESEARCH: Weekly Fixed Income Update",
         null,
         null,
         "13.0",
         "11852651.0",
         "Martey, Courage Kingsley",
         "4",
         null,
         "AssetType",
         "FixedIncome",
         "USTreasuries",
         null,
         null,
         "TreasuryBills",
         "Investment",
         "Fundamental",
         "Weekly",
         "Africa",
         "Egypt",
         "Yes"
        ],
        [
         "3",
         "08-Jan-2019 13:11",
         "2019",
         "216246",
         "Srichandra, Andrew",
         "3125872920",
         "7199",
         "Driehaus Capital Management, LLC",
         "7199",
         "Driehaus Capital Management, LLC",
         "25 E. Erie  ",
         "Chicago",
         "IL",
         "US",
         "6TUL7USBEJBRAR6IDDK423MUXM6",
         "628c6fd12c173f752189449bc4a6e73b",
         "D1A0C9D2137011E9B90BFC4D14941755",
         "08-Jan-2019 13:10",
         "08-Jan-2019 13:10",
         ". Databank Daily Market Review - (8th January, 2019)",
         null,
         null,
         "16.0",
         "13292912.0",
         "Asante, Lawrencia",
         "5",
         null,
         "Market",
         "Commodity",
         "Stock",
         "2225.0",
         "Agricultural Commodities/Milling",
         null,
         "Investment",
         "Fundamental",
         "Daily",
         "Africa",
         "Ghana",
         "Yes"
        ],
        [
         "4",
         "08-Jan-2019 13:11",
         "2019",
         "833192",
         "Kelly, Georgia",
         "5184628355",
         "1437969",
         "BAML - GWIM 1100 Pennington",
         "1484773",
         "BAML Wealth Albany - WZ3291",
         "69 State St  ",
         "Albany",
         "NY",
         "US",
         "6TUL7USBEJBRAR6IDDK423MUXM6",
         "628c6fd12c173f752189449bc4a6e73b",
         "bfdcc5aa186f46abb13dbca48529b49d",
         "08-Jan-2019 13:10",
         "08-Jan-2019 13:10",
         ". Databank Daily Market Review - (8th January, 2019)",
         null,
         null,
         "16.0",
         "13292912.0",
         "Asante, Lawrencia",
         "5",
         null,
         "Market",
         "Commodity",
         "Stock",
         "2225.0",
         "Agricultural Commodities/Milling",
         null,
         "Investment",
         "Fundamental",
         "Daily",
         "Africa",
         "Ghana",
         "Yes"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/time read</th>\n",
       "      <th>Year</th>\n",
       "      <th>Reader ID (FactSet)</th>\n",
       "      <th>Reader name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Parent Firm ID (FactSet)</th>\n",
       "      <th>Parent Firm name</th>\n",
       "      <th>Firm ID (FactSet)</th>\n",
       "      <th>Firm name</th>\n",
       "      <th>Address</th>\n",
       "      <th>...</th>\n",
       "      <th>Asset Type</th>\n",
       "      <th>Primary Industry Code (FactSet)</th>\n",
       "      <th>Primary Industry Name (FactSet)</th>\n",
       "      <th>Security Type</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Research Approach</th>\n",
       "      <th>Periodicity</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Compilation Indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-Jan-2019 12:29</td>\n",
       "      <td>2019</td>\n",
       "      <td>216246</td>\n",
       "      <td>Srichandra, Andrew</td>\n",
       "      <td>3125872920</td>\n",
       "      <td>7199</td>\n",
       "      <td>Driehaus Capital Management, LLC</td>\n",
       "      <td>7199</td>\n",
       "      <td>Driehaus Capital Management, LLC</td>\n",
       "      <td>25 E. Erie</td>\n",
       "      <td>...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>Agricultural Commodities/Milling</td>\n",
       "      <td>Common</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-Jan-2019 12:33</td>\n",
       "      <td>2019</td>\n",
       "      <td>216246</td>\n",
       "      <td>Srichandra, Andrew</td>\n",
       "      <td>3125872920</td>\n",
       "      <td>7199</td>\n",
       "      <td>Driehaus Capital Management, LLC</td>\n",
       "      <td>7199</td>\n",
       "      <td>Driehaus Capital Management, LLC</td>\n",
       "      <td>25 E. Erie</td>\n",
       "      <td>...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>Agricultural Commodities/Milling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-Jan-2019 07:01</td>\n",
       "      <td>2019</td>\n",
       "      <td>833192</td>\n",
       "      <td>Kelly, Georgia</td>\n",
       "      <td>5184628355</td>\n",
       "      <td>1437969</td>\n",
       "      <td>BAML - GWIM 1100 Pennington</td>\n",
       "      <td>1484773</td>\n",
       "      <td>BAML Wealth Albany - WZ3291</td>\n",
       "      <td>69 State St</td>\n",
       "      <td>...</td>\n",
       "      <td>USTreasuries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TreasuryBills</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-Jan-2019 13:11</td>\n",
       "      <td>2019</td>\n",
       "      <td>216246</td>\n",
       "      <td>Srichandra, Andrew</td>\n",
       "      <td>3125872920</td>\n",
       "      <td>7199</td>\n",
       "      <td>Driehaus Capital Management, LLC</td>\n",
       "      <td>7199</td>\n",
       "      <td>Driehaus Capital Management, LLC</td>\n",
       "      <td>25 E. Erie</td>\n",
       "      <td>...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>Agricultural Commodities/Milling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2019 13:11</td>\n",
       "      <td>2019</td>\n",
       "      <td>833192</td>\n",
       "      <td>Kelly, Georgia</td>\n",
       "      <td>5184628355</td>\n",
       "      <td>1437969</td>\n",
       "      <td>BAML - GWIM 1100 Pennington</td>\n",
       "      <td>1484773</td>\n",
       "      <td>BAML Wealth Albany - WZ3291</td>\n",
       "      <td>69 State St</td>\n",
       "      <td>...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>Agricultural Commodities/Milling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date/time read  Year Reader ID (FactSet)         Reader name  \\\n",
       "0  03-Jan-2019 12:29  2019              216246  Srichandra, Andrew   \n",
       "1  04-Jan-2019 12:33  2019              216246  Srichandra, Andrew   \n",
       "2  08-Jan-2019 07:01  2019              833192      Kelly, Georgia   \n",
       "3  08-Jan-2019 13:11  2019              216246  Srichandra, Andrew   \n",
       "4  08-Jan-2019 13:11  2019              833192      Kelly, Georgia   \n",
       "\n",
       "        Phone  Parent Firm ID (FactSet)                  Parent Firm name  \\\n",
       "0  3125872920                      7199  Driehaus Capital Management, LLC   \n",
       "1  3125872920                      7199  Driehaus Capital Management, LLC   \n",
       "2  5184628355                   1437969       BAML - GWIM 1100 Pennington   \n",
       "3  3125872920                      7199  Driehaus Capital Management, LLC   \n",
       "4  5184628355                   1437969       BAML - GWIM 1100 Pennington   \n",
       "\n",
       "   Firm ID (FactSet)                         Firm name        Address  ...  \\\n",
       "0               7199  Driehaus Capital Management, LLC   25 E. Erie    ...   \n",
       "1               7199  Driehaus Capital Management, LLC   25 E. Erie    ...   \n",
       "2            1484773       BAML Wealth Albany - WZ3291  69 State St    ...   \n",
       "3               7199  Driehaus Capital Management, LLC   25 E. Erie    ...   \n",
       "4            1484773       BAML Wealth Albany - WZ3291  69 State St    ...   \n",
       "\n",
       "     Asset Type Primary Industry Code (FactSet)  \\\n",
       "0         Stock                          2225.0   \n",
       "1         Stock                          2225.0   \n",
       "2  USTreasuries                             NaN   \n",
       "3         Stock                          2225.0   \n",
       "4         Stock                          2225.0   \n",
       "\n",
       "    Primary Industry Name (FactSet)  Security Type  Discipline  \\\n",
       "0  Agricultural Commodities/Milling         Common  Investment   \n",
       "1  Agricultural Commodities/Milling            NaN  Investment   \n",
       "2                               NaN  TreasuryBills  Investment   \n",
       "3  Agricultural Commodities/Milling            NaN  Investment   \n",
       "4  Agricultural Commodities/Milling            NaN  Investment   \n",
       "\n",
       "  Research Approach Periodicity  Region Country Compilation Indicator  \n",
       "0       Fundamental       Daily  Africa   Ghana                   Yes  \n",
       "1       Fundamental      Weekly  Africa   Ghana                   Yes  \n",
       "2       Fundamental      Weekly  Africa   Egypt                   Yes  \n",
       "3       Fundamental       Daily  Africa   Ghana                   Yes  \n",
       "4       Fundamental       Daily  Africa   Ghana                   Yes  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5cabb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Column Names:\n",
      "    1. Date/time read\n",
      "    2. Year\n",
      "    3. Reader ID (FactSet)\n",
      "    4. Reader name\n",
      "    5. Phone\n",
      "    6. Parent Firm ID (FactSet)\n",
      "    7. Parent Firm name\n",
      "    8. Firm ID (FactSet)\n",
      "    9. Firm name\n",
      "   10. Address\n",
      "   11. City\n",
      "   12. State\n",
      "   13. Reader Country\n",
      "   14. Doc ID (contributor)\n",
      "   15. Doc ID (FactSet)\n",
      "   16. Readership Event ID (FactSet)\n",
      "   17. Date/time published\n",
      "   18. Date/time received\n",
      "   19. Report title\n",
      "   20. Primary issuer Ticker\n",
      "   21. Primary issuer name\n",
      "   22. Primary analyst code (contributor)\n",
      "   23. Primary analyst code (FactSet)\n",
      "   24. Primary analyst name\n",
      "   25. Number of pages in report\n",
      "   26. Report Purpose\n",
      "   27. Report Focus\n",
      "   28. Asset Class\n",
      "   29. Asset Type\n",
      "   30. Primary Industry Code (FactSet)\n",
      "   31. Primary Industry Name (FactSet)\n",
      "   32. Security Type\n",
      "   33. Discipline\n",
      "   34. Research Approach\n",
      "   35. Periodicity\n",
      "   36. Region\n",
      "   37. Country\n",
      "   38. Compilation Indicator\n"
     ]
    }
   ],
   "source": [
    "# Display columns\n",
    "print(\"\\n Column Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30fe529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data Types:\n",
      "Date/time read                         object\n",
      "Year                                    int64\n",
      "Reader ID (FactSet)                    object\n",
      "Reader name                            object\n",
      "Phone                                  object\n",
      "Parent Firm ID (FactSet)                int64\n",
      "Parent Firm name                       object\n",
      "Firm ID (FactSet)                       int64\n",
      "Firm name                              object\n",
      "Address                                object\n",
      "City                                   object\n",
      "State                                  object\n",
      "Reader Country                         object\n",
      "Doc ID (contributor)                   object\n",
      "Doc ID (FactSet)                       object\n",
      "Readership Event ID (FactSet)          object\n",
      "Date/time published                    object\n",
      "Date/time received                     object\n",
      "Report title                           object\n",
      "Primary issuer Ticker                  object\n",
      "Primary issuer name                    object\n",
      "Primary analyst code (contributor)    float64\n",
      "Primary analyst code (FactSet)        float64\n",
      "Primary analyst name                   object\n",
      "Number of pages in report               int64\n",
      "Report Purpose                         object\n",
      "Report Focus                           object\n",
      "Asset Class                            object\n",
      "Asset Type                             object\n",
      "Primary Industry Code (FactSet)       float64\n",
      "Primary Industry Name (FactSet)        object\n",
      "Security Type                          object\n",
      "Discipline                             object\n",
      "Research Approach                      object\n",
      "Periodicity                            object\n",
      "Region                                 object\n",
      "Country                                object\n",
      "Compilation Indicator                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data types\n",
    "print(\"\\n Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b03faa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Basic Statistics:**\n",
      "           Date/time read         Year  Reader ID (FactSet)   Reader name  \\\n",
      "count                5976  5976.000000               5976.0          5976   \n",
      "unique               3679          NaN                768.0           762   \n",
      "top     17-Jun-2025 10:48          NaN             824137.0  Bacon, Lorel   \n",
      "freq                   34          NaN               1678.0          1678   \n",
      "mean                  NaN  2022.438755                  NaN           NaN   \n",
      "std                   NaN     2.033592                  NaN           NaN   \n",
      "min                   NaN  2019.000000                  NaN           NaN   \n",
      "25%                   NaN  2021.000000                  NaN           NaN   \n",
      "50%                   NaN  2023.000000                  NaN           NaN   \n",
      "75%                   NaN  2024.000000                  NaN           NaN   \n",
      "max                   NaN  2025.000000                  NaN           NaN   \n",
      "\n",
      "               Phone  Parent Firm ID (FactSet)        Parent Firm name  \\\n",
      "count   4.999000e+03              5.976000e+03                    5976   \n",
      "unique  5.840000e+02                       NaN                     416   \n",
      "top     2.127089e+09                       NaN  Bessemer Trust Company   \n",
      "freq    1.678000e+03                       NaN                    1684   \n",
      "mean             NaN              3.144776e+05                     NaN   \n",
      "std              NaN              4.993862e+05                     NaN   \n",
      "min              NaN              2.000000e+01                     NaN   \n",
      "25%              NaN              9.400000e+01                     NaN   \n",
      "50%              NaN              5.693000e+03                     NaN   \n",
      "75%              NaN              5.254230e+05                     NaN   \n",
      "max              NaN              3.159292e+06                     NaN   \n",
      "\n",
      "        Firm ID (FactSet)               Firm name            Address  ...  \\\n",
      "count        5.976000e+03                    5976               5976  ...   \n",
      "unique                NaN                     548                588  ...   \n",
      "top                   NaN  Bessemer Trust Company  1271 6th Avenue    ...   \n",
      "freq                  NaN                    1679               1680  ...   \n",
      "mean         6.177608e+05                     NaN                NaN  ...   \n",
      "std          6.952196e+05                     NaN                NaN  ...   \n",
      "min          2.000000e+01                     NaN                NaN  ...   \n",
      "25%          9.400000e+01                     NaN                NaN  ...   \n",
      "50%          4.383650e+05                     NaN                NaN  ...   \n",
      "75%          9.590570e+05                     NaN                NaN  ...   \n",
      "max          3.239041e+06                     NaN                NaN  ...   \n",
      "\n",
      "       Asset Type Primary Industry Code (FactSet)  \\\n",
      "count        5377                     3828.000000   \n",
      "unique         10                             NaN   \n",
      "top         Stock                             NaN   \n",
      "freq         4433                             NaN   \n",
      "mean          NaN                     3257.367816   \n",
      "std           NaN                     1272.672431   \n",
      "min           NaN                     1105.000000   \n",
      "25%           NaN                     2225.000000   \n",
      "50%           NaN                     2410.000000   \n",
      "75%           NaN                     4810.000000   \n",
      "max           NaN                     6010.000000   \n",
      "\n",
      "       Primary Industry Name (FactSet) Security Type  Discipline  \\\n",
      "count                             3828          2735        5976   \n",
      "unique                              34            10           3   \n",
      "top                     Regional Banks        Common  Investment   \n",
      "freq                               714          1881        5733   \n",
      "mean                               NaN           NaN         NaN   \n",
      "std                                NaN           NaN         NaN   \n",
      "min                                NaN           NaN         NaN   \n",
      "25%                                NaN           NaN         NaN   \n",
      "50%                                NaN           NaN         NaN   \n",
      "75%                                NaN           NaN         NaN   \n",
      "max                                NaN           NaN         NaN   \n",
      "\n",
      "       Research Approach Periodicity  Region Country Compilation Indicator  \n",
      "count               5503        4704    5895    5224                  5976  \n",
      "unique                 1           4       7      25                     2  \n",
      "top          Fundamental       Daily  Africa   Ghana                   Yes  \n",
      "freq                5503        3344    5773    2964                  4866  \n",
      "mean                 NaN         NaN     NaN     NaN                   NaN  \n",
      "std                  NaN         NaN     NaN     NaN                   NaN  \n",
      "min                  NaN         NaN     NaN     NaN                   NaN  \n",
      "25%                  NaN         NaN     NaN     NaN                   NaN  \n",
      "50%                  NaN         NaN     NaN     NaN                   NaN  \n",
      "75%                  NaN         NaN     NaN     NaN                   NaN  \n",
      "max                  NaN         NaN     NaN     NaN                   NaN  \n",
      "\n",
      "[11 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics\n",
    "print(\"\\n **Basic Statistics:**\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a9b3b",
   "metadata": {},
   "source": [
    "### DATA CLEANING & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57db1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Comprehensive data cleaning\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA CLEANING & PREPROCESSING\")\n",
    "    print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7db924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9040633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing Values Analysis:\n",
      "                                    Missing_Count  Percentage\n",
      "Report Purpose                               5314   88.922356\n",
      "Primary issuer Ticker                        4979   83.316600\n",
      "Primary issuer name                          4955   82.914993\n",
      "Security Type                                3241   54.233601\n",
      "Primary Industry Name (FactSet)              2148   35.943775\n",
      "Primary Industry Code (FactSet)              2148   35.943775\n",
      "Periodicity                                  1272   21.285141\n",
      "Phone                                         977   16.348728\n",
      "State                                         835   13.972557\n",
      "Country                                       752   12.583668\n",
      "Asset Type                                    599   10.023427\n",
      "Research Approach                             473    7.914993\n",
      "Report Focus                                  249    4.166667\n",
      "Primary analyst code (contributor)            211    3.530790\n",
      "Asset Class                                   202    3.380187\n",
      "Primary analyst name                          128    2.141901\n",
      "Region                                         81    1.355422\n",
      "Primary analyst code (FactSet)                 77    1.288487\n",
      "Doc ID (contributor)                           36    0.602410\n"
     ]
    }
   ],
   "source": [
    "# Missing values analysis\n",
    "print(\"\\n Missing Values Analysis:\")\n",
    "missing = df_clean.isnull().sum()\n",
    "missing_pct = (missing / len(df_clean)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dedf7afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Converted Date/time read to datetime\n",
      " Converted Date/time published to datetime\n",
      " Converted Date/time received to datetime\n"
     ]
    }
   ],
   "source": [
    "# Date/time processing\n",
    "date_columns = [col for col in df_clean.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "for col in date_columns:\n",
    "    if col in df_clean.columns:\n",
    "        try:\n",
    "            df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "            print(f\" Converted {col} to datetime\")\n",
    "        except:\n",
    "            print(f\" Could not convert {col} to datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07589dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted temporal features\n"
     ]
    }
   ],
   "source": [
    "# Extract temporal features\n",
    "if 'Date/time read' in df_clean.columns:\n",
    "    df_clean['Year'] = df_clean['Date/time read'].dt.year\n",
    "    df_clean['Month'] = df_clean['Date/time read'].dt.month\n",
    "    df_clean['Quarter'] = df_clean['Date/time read'].dt.quarter\n",
    "    df_clean['DayOfWeek'] = df_clean['Date/time read'].dt.day_name()\n",
    "    df_clean['Hour'] = df_clean['Date/time read'].dt.hour\n",
    "    print(\" Extracted temporal features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362d8160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned 29 text columns\n"
     ]
    }
   ],
   "source": [
    "# Clean text columns (strip whitespace)\n",
    "text_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "for col in text_cols:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "print(f\" Cleaned {len(text_cols)} text columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "700488c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Handle duplicates\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f\"\\n Duplicate rows: {duplicates:,}\")\n",
    "if duplicates > 0:\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\" Removed {duplicates:,} duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "253f9828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data Quality Score: 99.03%\n",
      " Clean dataset: 5,976 rows\n"
     ]
    }
   ],
   "source": [
    "    # Data quality score\n",
    "quality_score = ((1 - df_clean.isnull().sum().sum() / (len(df_clean) * len(df_clean.columns))) * 100)\n",
    "print(f\"\\n Data Quality Score: {quality_score:.2f}%\")\n",
    "print(f\" Clean dataset: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134cdf5",
   "metadata": {},
   "source": [
    "### KEY PERFORMANCE INDICATORS (KPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24b09117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kpis(df):\n",
    "    \"\"\"Calculate key performance indicators\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY PERFORMANCE INDICATORS (KPIs)\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c8c3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3a1a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total readership\n",
    "kpis['total_reads'] = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a8315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique metrics\n",
    "if 'Reader ID (FactSet)' in df.columns:\n",
    "    kpis['unique_readers'] = df['Reader ID (FactSet)'].nunique()\n",
    "if 'Firm ID (FactSet)' in df.columns:\n",
    "    kpis['unique_firms'] = df['Firm ID (FactSet)'].nunique()\n",
    "if 'Parent Firm ID (FactSet)' in df.columns:\n",
    "    kpis['unique_parent_firms'] = df['Parent Firm ID (FactSet)'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc138c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic reach\n",
    "if 'Country' in df.columns:\n",
    "    kpis['countries_reached'] = df['Country'].nunique()\n",
    "if 'Region' in df.columns:\n",
    "    kpis['regions_reached'] = df['Region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80629e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report metrics\n",
    "if 'Report title' in df.columns:\n",
    "    kpis['unique_reports'] = df['Report title'].nunique()\n",
    "if 'Primary analyst name' in df.columns:\n",
    "    kpis['active_analysts'] = df['Primary analyst name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b0dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset and Industry coverage\n",
    "if 'Asset Class' in df.columns:\n",
    "    kpis['asset_classes'] = df['Asset Class'].nunique()\n",
    "if 'Asset Type' in df.columns:\n",
    "    kpis['asset_types'] = df['Asset Type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43031ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement metrics\n",
    "if 'Number of pages in report' in df.columns:\n",
    "    kpis['avg_report_length'] = df['Number of pages in report'].mean()\n",
    "    kpis['total_pages_read'] = df['Number of pages in report'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d5fbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based metrics\n",
    "if 'Year' in df.columns:\n",
    "    kpis['years_covered'] = df['Year'].nunique()\n",
    "    kpis['date_range'] = f\"{df['Year'].min()} - {df['Year'].max()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "933a940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OVERALL METRICS:\n",
      "   • Total Reads: 5,976\n",
      "   • Unique Readers: 768\n",
      "   • Unique Firms: 595\n",
      "   • Unique Parent Firms: 416\n",
      "   • Countries Reached: 25\n",
      "   • Regions Reached: 7\n",
      "   • Unique Reports: 1,810\n",
      "   • Active Analysts: 23\n",
      "   • Asset Classes: 4\n",
      "   • Asset Types: 10\n",
      "   • Avg Report Length: 5.21\n",
      "   • Total Pages Read: 31109\n",
      "   • Years Covered: 7\n",
      "   • Date Range: 2019 - 2025\n"
     ]
    }
   ],
   "source": [
    "# Print KPIs\n",
    "print(\"\\n OVERALL METRICS:\")\n",
    "for key, value in kpis.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   • {key.replace('_', ' ').title()}: {value:,.2f}\")\n",
    "    else:\n",
    "        print(f\"   • {key.replace('_', ' ').title()}: {value:,}\" if isinstance(value, int) else f\"   • {key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee654b",
   "metadata": {},
   "source": [
    "### GEOGRAPHIC ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a729efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geographic_analysis(df):\n",
    "    \"\"\"Analyze readership by region and country\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GEOGRAPHIC ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "910cd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bd23295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP REGIONS BY READERSHIP:\n",
      "                 Total_Reads  Unique_Firms  Percentage\n",
      "Region                                                \n",
      "Africa                  5773           559       97.93\n",
      "Americas                  70            28        1.19\n",
      "EMEA                      28            28        0.47\n",
      "AsiaExJapan               12             7        0.20\n",
      "AsiaPac                   10             4        0.17\n",
      "EmergingMarkets            1             1        0.02\n",
      "NorthAmerica               1             1        0.02\n"
     ]
    }
   ],
   "source": [
    "# Region analysis\n",
    "if 'Region' in df.columns:\n",
    "    region_stats = df.groupby('Region').agg({\n",
    "        'Reader ID (FactSet)': 'count',\n",
    "        'Firm ID (FactSet)': 'nunique'\n",
    "    }).round(2)\n",
    "    region_stats.columns = ['Total_Reads', 'Unique_Firms']\n",
    "    region_stats = region_stats.sort_values('Total_Reads', ascending=False)\n",
    "    region_stats['Percentage'] = (region_stats['Total_Reads'] / region_stats['Total_Reads'].sum() * 100).round(2)\n",
    "        \n",
    "    print(\"\\n TOP REGIONS BY READERSHIP:\")\n",
    "    print(region_stats.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7261a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['region_stats'] = region_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29a70c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 20 COUNTRIES BY READERSHIP:\n",
      "                           Total_Reads  Unique_Firms  Percentage\n",
      "Country                                                         \n",
      "Ghana                             2964           396       56.74\n",
      "Egypt                             1049           140       20.08\n",
      "Canada                             666            86       12.75\n",
      "India                              192            20        3.68\n",
      "Australia                           96            13        1.84\n",
      "Togo                                49            26        0.94\n",
      "Kenya                               33            12        0.63\n",
      "Zambia                              30             8        0.57\n",
      "United Kingdom                      22            21        0.42\n",
      "Nigeria                             22             6        0.42\n",
      "China (People's Republic)           16             9        0.31\n",
      "United States                       16            13        0.31\n",
      "South Africa                        16             7        0.31\n",
      "Colombia                            15             4        0.29\n",
      "Denmark                             10            10        0.19\n",
      "Botswana                             5             5        0.10\n",
      "Ukraine                              5             3        0.10\n",
      "Saudi Arabia                         4             4        0.08\n",
      "Switzerland                          4             2        0.08\n",
      "Gambia                               2             2        0.04\n"
     ]
    }
   ],
   "source": [
    "# Country analysis\n",
    "if 'Country' in df.columns:\n",
    "    country_stats = df.groupby('Country').agg({\n",
    "        'Reader ID (FactSet)': 'count',\n",
    "        'Firm ID (FactSet)': 'nunique'\n",
    "        }).round(2)\n",
    "    country_stats.columns = ['Total_Reads', 'Unique_Firms']\n",
    "    country_stats = country_stats.sort_values('Total_Reads', ascending=False)\n",
    "    country_stats['Percentage'] = (country_stats['Total_Reads'] / country_stats['Total_Reads'].sum() * 100).round(2)\n",
    "        \n",
    "    print(\"\\n TOP 20 COUNTRIES BY READERSHIP:\")\n",
    "    print(country_stats.head(20))\n",
    "    results['country_stats'] = country_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77611265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 20 REGION-COUNTRY COMBINATIONS:\n",
      "         Region                    Country  Reads\n",
      "9        Africa                      Ghana   2964\n",
      "6        Africa                      Egypt   1049\n",
      "3        Africa                     Canada    613\n",
      "10       Africa                      India    184\n",
      "0        Africa                  Australia     86\n",
      "21     Americas                     Canada     52\n",
      "16       Africa                       Togo     49\n",
      "11       Africa                      Kenya     33\n",
      "20       Africa                     Zambia     30\n",
      "12       Africa                    Nigeria     22\n",
      "23     Americas              United States     16\n",
      "31         EMEA             United Kingdom     16\n",
      "14       Africa               South Africa     16\n",
      "5        Africa                   Colombia     15\n",
      "4        Africa  China (People's Republic)     13\n",
      "29         EMEA                    Denmark     10\n",
      "28      AsiaPac                  Australia     10\n",
      "26  AsiaExJapan                      India      8\n",
      "2        Africa                   Botswana      5\n",
      "19       Africa             United Kingdom      5\n"
     ]
    }
   ],
   "source": [
    "# Region-Country breakdown\n",
    "if 'Region' in df.columns and 'Country' in df.columns:\n",
    "    region_country = df.groupby(['Region', 'Country']).size().reset_index(name='Reads')\n",
    "    region_country = region_country.sort_values('Reads', ascending=False)\n",
    "    print(\"\\n TOP 20 REGION-COUNTRY COMBINATIONS:\")\n",
    "    print(region_country.head(20))\n",
    "    results['region_country'] = region_country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a2ea14",
   "metadata": {},
   "source": [
    "### TEMPORAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac5cdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_analysis(df):\n",
    "    \"\"\"Analyze trends over time\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TEMPORAL ANALYSIS\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27571673",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47c98e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " YEARLY TRENDS:\n",
      "      Total_Reads  Unique_Firms  YoY_Growth\n",
      "Year                                       \n",
      "2019          730           163         NaN\n",
      "2020          699           113   -4.246575\n",
      "2021          577            95  -17.453505\n",
      "2022          588            89    1.906412\n",
      "2023         1137            93   93.367347\n",
      "2024         1085            68   -4.573439\n",
      "2025         1160           189    6.912442\n"
     ]
    }
   ],
   "source": [
    "# Yearly trends\n",
    "if 'Year' in df.columns:\n",
    "    yearly = df.groupby('Year').agg({\n",
    "        'Reader ID (FactSet)': 'count',\n",
    "        'Firm ID (FactSet)': 'nunique',\n",
    "    }).round(2)\n",
    "    yearly.columns = ['Total_Reads', 'Unique_Firms']\n",
    "    yearly['YoY_Growth'] = yearly['Total_Reads'].pct_change() * 100\n",
    "        \n",
    "    print(\"\\n YEARLY TRENDS:\")\n",
    "    print(yearly)\n",
    "    results['yearly'] = yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3852c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Quarterly trends\n",
    "if 'Year' in df.columns and 'Quarter' in df.columns:\n",
    "    df['Year_Quarter'] = df['Year'].astype(str) + '-Q' + df['Quarter'].astype(str)\n",
    "    quarterly = df.groupby('Year_Quarter')['Reader ID (FactSet)'].count().reset_index()\n",
    "    quarterly.columns = ['Period', 'Reads']\n",
    "    print(\"\\n QUARTERLY TRENDS (Last 12 quarters):\")\n",
    "    print(quarterly.tail(12))\n",
    "    results['quarterly'] = quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d7f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly patterns\n",
    "if 'Month' in df.columns:\n",
    "    monthly = df.groupby('Month')['Reader ID (FactSet)'].count().reset_index()\n",
    "    monthly.columns = ['Month', 'Reads']\n",
    "    month_names = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n",
    "                    7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    monthly['Month_Name'] = monthly['Month'].map(month_names)\n",
    "    print(\"\\n MONTHLY PATTERNS:\")\n",
    "    print(monthly)\n",
    "    results['monthly'] = monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfa012",
   "metadata": {},
   "source": [
    "### FIRM & ANALYST ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ade80608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firm_analyst_analysis(df):\n",
    "    \"\"\"Analyze firms and analysts\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FIRM & ANALYST ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae8f0770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 20 FIRMS BY READERSHIP:\n",
      "                                              Total_Reads  Unique_Readers\n",
      "Firm name                                                                \n",
      "Bessemer Trust Company                               1679               2\n",
      "Permodalan Nasional Berhad (PNB)                      666               1\n",
      "JPM Private Bank - 277 Park                           476               1\n",
      "Charles Schwab & Co., Inc                             348               3\n",
      "BAML Wealth Pennington - WA9749                       250               1\n",
      "Old Mutual Investment Group (Pty) Ltd.                162               3\n",
      "Fairfield Bush & Co                                   148               1\n",
      "Columbia University - Business School                 133               8\n",
      "Osborne Partners Capital Management                   119               1\n",
      "Montrusco Bolton Investments Inc.                     118               1\n",
      "PNC Wealth Management                                 112              12\n",
      "Bank of America Private Wealth Management              99              10\n",
      "BAML Wealth Kansas City - WZ3701                       76               1\n",
      "BAML Wealth New York - W04701                          72               1\n",
      "Tanager Wealth Management                              56               2\n",
      "Virtus Investment Partners                             56               6\n",
      "Allianz Global Investors U.S.                          50               8\n",
      "Copal Amba (for Julius Baer), Bangalore                46               1\n",
      "Equinox Partners Investment Management, LLC.           41               9\n",
      "BAML Wealth - WZ5911 - Richmond                        38               1\n"
     ]
    }
   ],
   "source": [
    "# Top firms\n",
    "if 'Firm name' in df.columns:\n",
    "    top_firms = df.groupby('Firm name').agg({\n",
    "        'Reader ID (FactSet)': 'count',\n",
    "        'Reader name' : 'nunique'\n",
    "    }).round(2)\n",
    "    top_firms.columns = ['Total_Reads', 'Unique_Readers']\n",
    "    top_firms = top_firms.sort_values('Total_Reads', ascending=False)\n",
    "    print(\"\\n TOP 20 FIRMS BY READERSHIP:\")\n",
    "    print(top_firms.head(20))\n",
    "    results['top_firms'] = top_firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef34bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 20 PARENT FIRMS:\n",
      "                                                    Total_Reads  \\\n",
      "Parent Firm name                                                  \n",
      "Bessemer Trust Company                                     1684   \n",
      "Permodalan Nasional Berhad (PNB)                            666   \n",
      "JPMorgan Investment Management                              524   \n",
      "BAML - GWIM 1100 Pennington                                 476   \n",
      "Charles Schwab & Co., Inc.                                  354   \n",
      "Old Mutual Investment Group (Pty) Ltd.                      164   \n",
      "Fairfield Bush & Co                                         148   \n",
      "Columbia University - Business School                       133   \n",
      "PNC Bank, National Association                              121   \n",
      "Osborne Partners Capital Management                         119   \n",
      "Montrusco Bolton Investments Inc.                           118   \n",
      "Bank of America Private Wealth Management                   103   \n",
      "Allianz Global Investors U.S. Holdings LLC                   57   \n",
      "Virtus Investment Partners                                   56   \n",
      "Tanager Wealth Management                                    56   \n",
      "DBS Bank Ltd                                                 53   \n",
      "Bank Julius Baer & Co. Ltd. - Zurich (Bahnhofst...           48   \n",
      "Equinox Partners Investment Management, LLC.                 41   \n",
      "D. E. Shaw & Co., L.P.                                       39   \n",
      "Poste Italiane S.p.A.                                        33   \n",
      "\n",
      "                                                    Unique_Subsidiaries  \n",
      "Parent Firm name                                                         \n",
      "Bessemer Trust Company                                                3  \n",
      "Permodalan Nasional Berhad (PNB)                                      1  \n",
      "JPMorgan Investment Management                                       13  \n",
      "BAML - GWIM 1100 Pennington                                          20  \n",
      "Charles Schwab & Co., Inc.                                            2  \n",
      "Old Mutual Investment Group (Pty) Ltd.                                2  \n",
      "Fairfield Bush & Co                                                   1  \n",
      "Columbia University - Business School                                 1  \n",
      "PNC Bank, National Association                                       12  \n",
      "Osborne Partners Capital Management                                   1  \n",
      "Montrusco Bolton Investments Inc.                                     1  \n",
      "Bank of America Private Wealth Management                            12  \n",
      "Allianz Global Investors U.S. Holdings LLC                            3  \n",
      "Virtus Investment Partners                                            2  \n",
      "Tanager Wealth Management                                             1  \n",
      "DBS Bank Ltd                                                          2  \n",
      "Bank Julius Baer & Co. Ltd. - Zurich (Bahnhofst...                    3  \n",
      "Equinox Partners Investment Management, LLC.                          1  \n",
      "D. E. Shaw & Co., L.P.                                                3  \n",
      "Poste Italiane S.p.A.                                                 1  \n"
     ]
    }
   ],
   "source": [
    "# Top parent firms\n",
    "if 'Parent Firm name' in df.columns:\n",
    "    top_parent = df.groupby('Parent Firm name').agg({\n",
    "        'Reader ID (FactSet)': 'count',\n",
    "        'Firm ID (FactSet)': 'nunique'\n",
    "    }).round(2)\n",
    "    top_parent.columns = ['Total_Reads', 'Unique_Subsidiaries']\n",
    "    top_parent = top_parent.sort_values('Total_Reads', ascending=False)\n",
    "    print(\"\\n TOP 20 PARENT FIRMS:\")\n",
    "    print(top_parent.head(20))\n",
    "    results['top_parent_firms'] = top_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "333080f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP 20 ANALYSTS BY READERSHIP:\n",
      "                          Total_Reads  Unique_Reports\n",
      "Primary analyst name                                 \n",
      "Azidizia, Emmanuel               1176             432\n",
      "Monanyun, Grace                  1141             285\n",
      "Martey, Courage Kingsley          776             189\n",
      "Asante, Lawrencia                 698             357\n",
      "Kporku, Edem Nicholas             377             177\n",
      "Dodoo, Naa Tsitse                 317             110\n",
      "Arkoh-koomson, Kweku              265              17\n",
      "Zilevu, Wilson                    264              22\n",
      "Sika Narteh, Mac-Jordan           256              19\n",
      "Mensah, Refuge                    147              30\n",
      "Lavie, Evelyn                     130              31\n",
      "Mensa-Bonsu, Afua Dankwa          126              33\n",
      "Amoaning-Kyei, Gideon              81              22\n",
      "Mensah, Reflector                  26               5\n",
      "Boahen, Alex                       18               9\n",
      "Agbozo, Joyce S A                  16               6\n",
      "Amable, Amanda                     11               1\n",
      "Agbozo, Joyce                       8               4\n",
      "Mensa-Bonsu, Afua                   4               4\n",
      "Opoku-Asiedu, Jesse                 4               2\n"
     ]
    }
   ],
   "source": [
    "# Top analysts\n",
    "if 'Primary analyst name' in df.columns:\n",
    "    top_analysts = df.groupby('Primary analyst name').agg({\n",
    "        'Reader ID (FactSet)': 'count',\n",
    "        'Report title': 'nunique'\n",
    "    }).round(2)\n",
    "    top_analysts.columns = ['Total_Reads', 'Unique_Reports']\n",
    "    top_analysts = top_analysts.sort_values('Total_Reads', ascending=False)\n",
    "    print(\"\\n TOP 20 ANALYSTS BY READERSHIP:\")\n",
    "    print(top_analysts.head(20))\n",
    "    results['top_analysts'] = top_analysts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbbc7c",
   "metadata": {},
   "source": [
    "### CONTENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c577fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_analysis(df):\n",
    "    \"\"\"Analyze report content characteristics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CONTENT ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a59973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ASSET CLASS DISTRIBUTION:\n",
      "   Asset_Class  Reads  Percentage\n",
      "2       Equity   4406       76.31\n",
      "3  FixedIncome    751       13.01\n",
      "1     Currency    438        7.59\n",
      "0    Commodity    179        3.10\n"
     ]
    }
   ],
   "source": [
    " # Asset class analysis\n",
    "if 'Asset Class' in df.columns:\n",
    "    asset_class = df.groupby('Asset Class')['Reader ID (FactSet)'].count().reset_index()\n",
    "    asset_class.columns = ['Asset_Class', 'Reads']\n",
    "    asset_class = asset_class.sort_values('Reads', ascending=False)\n",
    "    asset_class['Percentage'] = (asset_class['Reads'] / asset_class['Reads'].sum() * 100).round(2)\n",
    "    print(\"\\n ASSET CLASS DISTRIBUTION:\")\n",
    "    print(asset_class)\n",
    "    results['asset_class'] = asset_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcb63801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP ASSET TYPES:\n",
      "                      Asset_Type  Reads\n",
      "8                          Stock   4433\n",
      "9                   USTreasuries    703\n",
      "1                    Agriculture    112\n",
      "4                         Credit     62\n",
      "2  CollateralizedDebtObligations     27\n",
      "6                         Energy     19\n",
      "3       CorporateHighYieldCredit     13\n",
      "0                   AgencyCredit      4\n",
      "5                    Derivatives      3\n",
      "7                    Environment      1\n"
     ]
    }
   ],
   "source": [
    " #Asset type analysis\n",
    "if 'Asset Type' in df.columns:\n",
    "    asset_type = df.groupby('Asset Type')['Reader ID (FactSet)'].count().reset_index()\n",
    "    asset_type.columns = ['Asset_Type', 'Reads']\n",
    "    asset_type = asset_type.sort_values('Reads', ascending=False)\n",
    "    print(\"\\n TOP ASSET TYPES:\")\n",
    "    print(asset_type.head(15))\n",
    "    results['asset_type'] = asset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a753b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " REPORT FOCUS DISTRIBUTION:\n",
      "     Report_Focus  Reads\n",
      "6          Market   1947\n",
      "4           Index   1649\n",
      "5          Issuer   1038\n",
      "0      AssetClass    733\n",
      "3      Discipline    242\n",
      "9    SecurityType     60\n",
      "1       AssetType     42\n",
      "2         Country      7\n",
      "8  SectorIndustry      7\n",
      "7          Region      2\n"
     ]
    }
   ],
   "source": [
    "    # Report focus\n",
    "if 'Report Focus' in df.columns:\n",
    "    focus = df.groupby('Report Focus')['Reader ID (FactSet)'].count().reset_index()\n",
    "    focus.columns = ['Report_Focus', 'Reads']\n",
    "    focus = focus.sort_values('Reads', ascending=False)\n",
    "    print(\"\\n REPORT FOCUS DISTRIBUTION:\")\n",
    "    print(focus.head(10))\n",
    "    results['report_focus'] = focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2e4a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " REPORT PURPOSE DISTRIBUTION:\n",
      "     Purpose  Reads\n",
      "0     Action    613\n",
      "1  Education     31\n",
      "2  Influence     18\n"
     ]
    }
   ],
   "source": [
    "# Report purpose\n",
    "if 'Report Purpose' in df.columns:\n",
    "    purpose = df.groupby('Report Purpose')['Reader ID (FactSet)'].count().reset_index()\n",
    "    purpose.columns = ['Purpose', 'Reads']\n",
    "    purpose = purpose.sort_values('Reads', ascending=False)\n",
    "    print(\"\\n REPORT PURPOSE DISTRIBUTION:\")\n",
    "    print(purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec072570",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['report_purpose'] = purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb235cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RESEARCH APPROACH:\n",
      "      Approach  Reads\n",
      "0  Fundamental   5503\n"
     ]
    }
   ],
   "source": [
    "# Research approach\n",
    "if 'Research Approach' in df.columns:\n",
    "    approach = df.groupby('Research Approach')['Reader ID (FactSet)'].count().reset_index()\n",
    "    approach.columns = ['Approach', 'Reads']\n",
    "    approach = approach.sort_values('Reads', ascending=False)\n",
    "    print(\"\\n RESEARCH APPROACH:\")\n",
    "    print(approach)\n",
    "    results['research_approach'] = approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "feb95879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " REPORT LENGTH STATISTICS:\n",
      "count    5976.000000\n",
      "mean        5.205656\n",
      "std         3.800600\n",
      "min         1.000000\n",
      "25%         4.000000\n",
      "50%         5.000000\n",
      "75%         5.000000\n",
      "max        43.000000\n",
      "Name: Number of pages in report, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Page length analysis\n",
    "if 'Number of pages in report' in df.columns:\n",
    "    print(\"\\n REPORT LENGTH STATISTICS:\")\n",
    "    print(df['Number of pages in report'].describe())\n",
    "    results['page_stats'] = df['Number of pages in report'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f32ba",
   "metadata": {},
   "source": [
    "### INTERACTIVE VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b58bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a929d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access any component:\n",
    "results['kpis']   = kpis\n",
    "results['region_country'] = geo_results\n",
    "results['yearly']       = temporal_results\n",
    "results['data']         = df_clean\n",
    "results['top_firms']    = firm_results\n",
    "results['asset_types']  = content_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d66d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access any component:\n",
    "results['kpis'] = kpis\n",
    "\n",
    "# region_country: prefer geo_results if available, else keep existing\n",
    "results['region_country'] = geo_results if 'geo_results' in globals() else results.get('region_country')\n",
    "\n",
    "# yearly / temporal results: prefer temporal_results, then fallback to a 'yearly' dataframe, then existing value\n",
    "if 'temporal_results' in globals():\n",
    "\tresults['yearly'] = temporal_results\n",
    "elif 'yearly' in globals():\n",
    "\tresults['yearly'] = yearly\n",
    "else:\n",
    "\tresults['yearly'] = results.get('yearly')\n",
    "\n",
    "results['data'] = df_clean\n",
    "\n",
    "# top_firms and asset_types with safe fallbacks\n",
    "results['top_firms'] = firm_results if 'firm_results' in globals() else results.get('top_firms')\n",
    "results['asset_types'] = content_results if 'content_results' in globals() else results.get('asset_types')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1329e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_dashboard(df_clean,region_country, temporal_results, firm_results, content_results):\n",
    "    \"\"\"Create comprehensive interactive dashboard\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CREATING INTERACTIVE DASHBOARD\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    figures = {}\n",
    "\n",
    "    # Geographic Distribution - Treemap\n",
    "    if 'region_country' in geo_results:\n",
    "        fig1 = px.treemap(geo_results['region_country'].head(50),\n",
    "                          path=['Region', 'Country'],\n",
    "                          values='Reads',\n",
    "                          title=' Geographic Distribution: Readership by Region & Country',\n",
    "                          color='Reads',\n",
    "                          color_continuous_scale='Blues')\n",
    "        fig1.update_layout(height=600)\n",
    "        figures['geo_treemap'] = fig1\n",
    "        print(\"Created geographic treemap\")\n",
    "\n",
    "    # Top Countries Bar Chart\n",
    "    if 'country_stats' in geo_results:\n",
    "        top_countries = geo_results['country_stats'].head(15).reset_index()\n",
    "        fig2 = px.bar(top_countries,\n",
    "                      x='Total_Reads',\n",
    "                      y='Country',\n",
    "                      orientation='h',\n",
    "                      title=' Top 15 Countries by Readership',\n",
    "                      labels={'Total_Reads': 'Number of Reads'},\n",
    "                      color='Total_Reads',\n",
    "                      color_continuous_scale='Viridis')\n",
    "        fig2.update_layout(height=600, yaxis={'categoryorder':'total ascending'})\n",
    "        figures['top_countries'] = fig2\n",
    "        print(\"✓ Created top countries chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "586715b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Countries Bar Chart\n",
    "# Ensure geo_results is available (fallback to global `results` if not provided)\n",
    "if 'geo_results' not in globals():\n",
    "    geo_results = results  # use previously computed results dict\n",
    "\n",
    "if 'country_stats' in geo_results:\n",
    "    top_countries = geo_results['country_stats'].head(15).reset_index()\n",
    "    fig2 = px.bar(top_countries,\n",
    "                  x='Total_Reads',\n",
    "                  y='Country',\n",
    "                  orientation='h',\n",
    "                  title=' Top 15 Countries by Readership',\n",
    "                  labels={'Total_Reads': 'Number of Reads'},\n",
    "                  color='Total_Reads',\n",
    "                  color_continuous_scale='Viridis')\n",
    "    fig2.update_layout(height=600, yaxis={'categoryorder':'total ascending'})\n",
    "    figures['top_countries'] = fig2\n",
    "    print(\"Created top countries chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a38b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert temporal_results['yearly'] to DataFrame: Data must be 1-dimensional, got ndarray of shape (416, 2) instead\n",
      "No yearly data available to create temporal trends.\n"
     ]
    }
   ],
   "source": [
    "# Ensure temporal_results is available (fallback to previously computed results)\n",
    "if 'temporal_results' not in globals():\n",
    "    temporal_results = results\n",
    "\n",
    "# Ensure figures dict exists\n",
    "if 'figures' not in globals():\n",
    "    figures = {}\n",
    "\n",
    "# Temporal Trends (robust conversion)\n",
    "if 'yearly' in temporal_results:\n",
    "    yr = temporal_results['yearly']\n",
    "    yearly_data = None\n",
    "    try:\n",
    "        # If it's already a DataFrame, ensure Year is a column\n",
    "        if isinstance(yr, pd.DataFrame):\n",
    "            yearly_data = yr.reset_index()\n",
    "            if 'Year' not in yearly_data.columns:\n",
    "                yearly_data = yearly_data.rename(columns={yearly_data.columns[0]: 'Year'})\n",
    "        # Handle numpy arrays / lists with sensible heuristics\n",
    "        elif isinstance(yr, (np.ndarray, list)):\n",
    "            arr = np.array(yr)\n",
    "            if arr.ndim == 1:\n",
    "                yearly_data = pd.DataFrame(arr, columns=['Total_Reads'])\n",
    "                yearly_data.index.name = 'Year'\n",
    "                yearly_data = yearly_data.reset_index()\n",
    "            elif arr.ndim == 2:\n",
    "                df_tmp = pd.DataFrame(arr)\n",
    "                first_col = df_tmp.iloc[:, 0]\n",
    "                # If first column looks like a year, use it as Year\n",
    "                if np.issubdtype(first_col.dtype, np.number) and ((first_col >= 1900) & (first_col <= 2100)).all():\n",
    "                    cols = ['Year'] + [f'col{i}' for i in range(1, df_tmp.shape[1])]\n",
    "                    df_tmp.columns = cols\n",
    "                    yearly_data = df_tmp\n",
    "                else:\n",
    "                    df_tmp.index.name = 'Year'\n",
    "                    yearly_data = df_tmp.reset_index()\n",
    "            else:\n",
    "                yearly_data = pd.DataFrame(arr.reshape(-1, 1)).reset_index().rename(columns={'index': 'Year', 0: 'Total_Reads'})\n",
    "        else:\n",
    "            yearly_data = pd.DataFrame(yr)\n",
    "            if 'Year' not in yearly_data.columns:\n",
    "                yearly_data = yearly_data.reset_index().rename(columns={'index': 'Year'})\n",
    "    except Exception as e:\n",
    "        print(\"Could not convert temporal_results['yearly'] to DataFrame:\", e)\n",
    "        yearly_data = None\n",
    "\n",
    "    if yearly_data is not None and not yearly_data.empty:\n",
    "        # Standardize common column names if possible\n",
    "        numeric_cols = yearly_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if 'Total_Reads' not in yearly_data.columns and numeric_cols:\n",
    "            # prefer a numeric column that isn't 'Year'\n",
    "            cand = [c for c in numeric_cols if c.lower() not in ('year', 'index')]\n",
    "            if cand:\n",
    "                yearly_data = yearly_data.rename(columns={cand[0]: 'Total_Reads'})\n",
    "            else:\n",
    "                yearly_data = yearly_data.rename(columns={numeric_cols[0]: 'Total_Reads'})\n",
    "\n",
    "        if 'Year' not in yearly_data.columns:\n",
    "            yearly_data = yearly_data.rename(columns={yearly_data.columns[0]: 'Year'})\n",
    "\n",
    "        # Compute YoY growth if missing and Total_Reads exists\n",
    "        if 'YoY_Growth' not in yearly_data.columns and 'Total_Reads' in yearly_data.columns:\n",
    "            yearly_data['YoY_Growth'] = yearly_data['Total_Reads'].pct_change() * 100\n",
    "\n",
    "        # Try to coerce Year to int for nicer x-axis labels\n",
    "        try:\n",
    "            yearly_data['Year'] = yearly_data['Year'].astype(int)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Create plots (guarding missing columns)\n",
    "        fig3 = make_subplots(rows=1, cols=2,\n",
    "                            subplot_titles=(' Total Reads Over Time', ' YoY Growth Rate'))\n",
    "\n",
    "        if 'Year' in yearly_data.columns and 'Total_Reads' in yearly_data.columns:\n",
    "            fig3.add_trace(go.Scatter(x=yearly_data['Year'], y=yearly_data['Total_Reads'],\n",
    "                                        mode='lines+markers', name='Total Reads',\n",
    "                                        line=dict(color='#1f77b4', width=3),\n",
    "                                        marker=dict(size=10)), row=1, col=1)\n",
    "        else:\n",
    "            # fallback: plot first numeric column against Year/index\n",
    "            ycols = [c for c in yearly_data.columns if c != 'Year' and pd.api.types.is_numeric_dtype(yearly_data[c])]\n",
    "            if ycols:\n",
    "                ycol = ycols[0]\n",
    "                fig3.add_trace(go.Scatter(x=yearly_data.get('Year', yearly_data.index), y=yearly_data[ycol],\n",
    "                                            mode='lines+markers', name=ycol,\n",
    "                                            line=dict(color='#1f77b4', width=3),\n",
    "                                            marker=dict(size=10)), row=1, col=1)\n",
    "\n",
    "        if 'Year' in yearly_data.columns and 'YoY_Growth' in yearly_data.columns:\n",
    "            fig3.add_trace(go.Bar(x=yearly_data['Year'], y=yearly_data['YoY_Growth'],\n",
    "                                    name='YoY Growth %', marker_color='#2ca02c'), row=1, col=2)\n",
    "        else:\n",
    "            # compute YoY from Total_Reads if possible\n",
    "            if 'Total_Reads' in yearly_data.columns:\n",
    "                fig3.add_trace(go.Bar(x=yearly_data.get('Year', yearly_data.index),\n",
    "                                      y=yearly_data['Total_Reads'].pct_change() * 100,\n",
    "                                      name='YoY Growth %', marker_color='#2ca02c'), row=1, col=2)\n",
    "            else:\n",
    "                fig3.add_trace(go.Bar(x=yearly_data.get('Year', yearly_data.index),\n",
    "                                      y=[None] * len(yearly_data),\n",
    "                                      name='YoY Growth %', marker_color='#2ca02c'), row=1, col=2)\n",
    "\n",
    "        fig3.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "        fig3.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "        fig3.update_yaxes(title_text=\"Number of Reads\", row=1, col=1)\n",
    "        fig3.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=2)\n",
    "        fig3.update_layout(height=500, showlegend=True, title_text=\"📅 Temporal Analysis\")\n",
    "        figures['temporal_trends'] = fig3\n",
    "        print(\"✓ Created temporal trends\")\n",
    "    else:\n",
    "        print(\"No yearly data available to create temporal trends.\")\n",
    "else:\n",
    "    print(\"No 'yearly' key in temporal_results to create temporal trends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a33fe984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly & Day of Week Heatmap\n",
    "if 'Month' in df.columns and 'DayOfWeek' in df.columns:\n",
    "    heatmap_data = df.groupby(['Month', 'DayOfWeek']).size().reset_index(name='Reads')\n",
    "    heatmap_pivot = heatmap_data.pivot(index='DayOfWeek', columns='Month', values='Reads')\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    heatmap_pivot = heatmap_pivot.reindex(day_order)\n",
    "        \n",
    "    fig4 = px.imshow(heatmap_pivot,\n",
    "                    labels=dict(x=\"Month\", y=\"Day of Week\", color=\"Reads\"),\n",
    "                    title=' Readership Heatmap: Day of Week vs Month',\n",
    "                    color_continuous_scale='YlOrRd')\n",
    "    fig4.update_layout(height=500)\n",
    "    figures['heatmap'] = fig4\n",
    "    print(\"✓ Created readership heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed7dd10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created top firms chart successfully\n"
     ]
    }
   ],
   "source": [
    "# Top Firms\n",
    "# Ensure firm_results is available (fallback to common results dicts)\n",
    "if 'firm_results' not in globals():\n",
    "    if 'geo_results' in globals():\n",
    "        firm_results = geo_results\n",
    "    elif 'results' in globals():\n",
    "        firm_results = results\n",
    "    else:\n",
    "        firm_results = {}\n",
    "\n",
    "# Ensure figures dict exists\n",
    "if 'figures' not in globals():\n",
    "    figures = {}\n",
    "\n",
    "if 'top_firms' in firm_results:\n",
    "    top_firms_data = firm_results['top_firms'].head(20).reset_index()\n",
    "    fig5 = px.bar(top_firms_data,\n",
    "                    y='Firm name',\n",
    "                    x='Total_Reads',\n",
    "                    orientation='h',\n",
    "                    title=' Top 20 Firms by Readership',\n",
    "                    labels={'Total_Reads': 'Number of Reads'},\n",
    "                    color='Total_Reads',\n",
    "                    color_continuous_scale='Plasma')\n",
    "    fig5.update_layout(height=700, yaxis={'categoryorder':'total ascending'})\n",
    "    figures['top_firms'] = fig5\n",
    "    print(\"Created top firms chart successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a1e4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created asset class pie chart successfully\n"
     ]
    }
   ],
   "source": [
    "# Asset Class Distribution\n",
    "# Ensure content_results is available (fallback to previously computed results)\n",
    "if 'content_results' not in globals():\n",
    "    if 'results' in globals():\n",
    "        content_results = results\n",
    "    elif 'geo_results' in globals():\n",
    "        content_results = geo_results\n",
    "    else:\n",
    "        content_results = {}\n",
    "\n",
    "# Ensure figures dict exists\n",
    "if 'figures' not in globals():\n",
    "    figures = {}\n",
    "\n",
    "if 'asset_class' in content_results and not content_results['asset_class'].empty:\n",
    "    fig6 = px.pie(content_results['asset_class'],\n",
    "                  values='Reads',\n",
    "                  names='Asset_Class',\n",
    "                  title=' Asset Class Distribution',\n",
    "                  hole=0.4)\n",
    "    fig6.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    fig6.update_layout(height=500)\n",
    "    figures['asset_class'] = fig6\n",
    "    print(\"Created asset class pie chart successfully\")\n",
    "else:\n",
    "    print(\"No asset_class data available to create pie chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a31f94d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created content characteristics successfully\n"
     ]
    }
   ],
   "source": [
    "# Research Approach & Purpose\n",
    "if 'research_approach' in content_results and 'report_purpose' in content_results:\n",
    "    fig7 = make_subplots(rows=1, cols=2,\n",
    "                        specs=[[{'type':'bar'}, {'type':'bar'}]],\n",
    "                        subplot_titles=('🔬 Research Approach', '📋 Report Purpose'))\n",
    "        \n",
    "    fig7.add_trace(go.Bar(x=content_results['research_approach']['Approach'],\n",
    "                            y=content_results['research_approach']['Reads'],\n",
    "                            marker_color='indianred'), row=1, col=1)\n",
    "        \n",
    "    fig7.add_trace(go.Bar(x=content_results['report_purpose']['Purpose'],\n",
    "                            y=content_results['report_purpose']['Reads'],\n",
    "                            marker_color='lightsalmon'), row=1, col=2)\n",
    "        \n",
    "    fig7.update_layout(height=500, showlegend=False, title_text=\"📊 Content Characteristics\")\n",
    "    figures['content_chars'] = fig7\n",
    "    print(\"Created content characteristics successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc806dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Created 4 interactive visualizations\n"
     ]
    }
   ],
   "source": [
    " #Quarterly Trends\n",
    "if 'quarterly' in temporal_results:\n",
    "    fig8 = px.line(temporal_results['quarterly'],\n",
    "                    x='Period',\n",
    "                    y='Reads',\n",
    "                    title='📊 Quarterly Readership Trends',\n",
    "                    markers=True)\n",
    "    fig8.update_traces(line=dict(width=3), marker=dict(size=8))\n",
    "    fig8.update_layout(height=500)\n",
    "    figures['quarterly'] = fig8\n",
    "    print(\"✓ Created quarterly trends\")\n",
    "    \n",
    "print(f\"\\n Created {len(figures)} interactive visualizations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26510b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temporal_trends': Figure({\n",
       "     'data': [{'line': {'color': '#1f77b4', 'width': 3},\n",
       "               'marker': {'size': 10},\n",
       "               'mode': 'lines+markers',\n",
       "               'name': 'Total Reads',\n",
       "               'type': 'scatter',\n",
       "               'x': {'bdata': '4wfkB+UH5gfnB+gH6Qc=', 'dtype': 'i2'},\n",
       "               'xaxis': 'x',\n",
       "               'y': {'bdata': '2gK7AkECTAJxBD0EiAQ=', 'dtype': 'i2'},\n",
       "               'yaxis': 'y'},\n",
       "              {'marker': {'color': '#2ca02c'},\n",
       "               'name': 'YoY Growth %',\n",
       "               'type': 'bar',\n",
       "               'x': {'bdata': '4wfkB+UH5gfnB+gH6Qc=', 'dtype': 'i2'},\n",
       "               'xaxis': 'x2',\n",
       "               'y': {'bdata': 'AAAAAAAA+H/Hjx8/fvwQwHNLducYdDHAHD/yXqqA/j/mFLycgldXQItMbI8zSxLAYZmuTFemG0A=',\n",
       "                     'dtype': 'f8'},\n",
       "               'yaxis': 'y2'}],\n",
       "     'layout': {'annotations': [{'font': {'size': 16},\n",
       "                                 'showarrow': False,\n",
       "                                 'text': ' Total Reads Over Time',\n",
       "                                 'x': 0.225,\n",
       "                                 'xanchor': 'center',\n",
       "                                 'xref': 'paper',\n",
       "                                 'y': 1.0,\n",
       "                                 'yanchor': 'bottom',\n",
       "                                 'yref': 'paper'},\n",
       "                                {'font': {'size': 16},\n",
       "                                 'showarrow': False,\n",
       "                                 'text': ' YoY Growth Rate',\n",
       "                                 'x': 0.775,\n",
       "                                 'xanchor': 'center',\n",
       "                                 'xref': 'paper',\n",
       "                                 'y': 1.0,\n",
       "                                 'yanchor': 'bottom',\n",
       "                                 'yref': 'paper'}],\n",
       "                'height': 500,\n",
       "                'showlegend': True,\n",
       "                'template': '...',\n",
       "                'title': {'text': '📅 Temporal Analysis'},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.45], 'title': {'text': 'Year'}},\n",
       "                'xaxis2': {'anchor': 'y2', 'domain': [0.55, 1.0], 'title': {'text': 'Year'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Number of Reads'}},\n",
       "                'yaxis2': {'anchor': 'x2', 'domain': [0.0, 1.0], 'title': {'text': 'Growth Rate (%)'}}}\n",
       " }),\n",
       " 'top_firms': Figure({\n",
       "     'data': [{'hovertemplate': 'Number of Reads=%{marker.color}<br>Firm name=%{y}<extra></extra>',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': {'bdata': 'jwaaAtwBXAH6AKIAlACFAHcAdgBwAGMATABIADgAOAAyAC4AKQAmAA==', 'dtype': 'i2'},\n",
       "                          'coloraxis': 'coloraxis',\n",
       "                          'pattern': {'shape': ''}},\n",
       "               'name': '',\n",
       "               'orientation': 'h',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': {'bdata': 'jwaaAtwBXAH6AKIAlACFAHcAdgBwAGMATABIADgAOAAyAC4AKQAmAA==', 'dtype': 'i2'},\n",
       "               'xaxis': 'x',\n",
       "               'y': array(['Bessemer Trust Company', 'Permodalan Nasional Berhad (PNB)',\n",
       "                           'JPM Private Bank - 277 Park', 'Charles Schwab & Co., Inc',\n",
       "                           'BAML Wealth Pennington - WA9749',\n",
       "                           'Old Mutual Investment Group (Pty) Ltd.', 'Fairfield Bush & Co',\n",
       "                           'Columbia University - Business School',\n",
       "                           'Osborne Partners Capital Management',\n",
       "                           'Montrusco Bolton Investments Inc.', 'PNC Wealth Management',\n",
       "                           'Bank of America Private Wealth Management',\n",
       "                           'BAML Wealth Kansas City - WZ3701', 'BAML Wealth New York - W04701',\n",
       "                           'Tanager Wealth Management', 'Virtus Investment Partners',\n",
       "                           'Allianz Global Investors U.S.',\n",
       "                           'Copal Amba (for Julius Baer), Bangalore',\n",
       "                           'Equinox Partners Investment Management, LLC.',\n",
       "                           'BAML Wealth - WZ5911 - Richmond'], dtype=object),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'coloraxis': {'colorbar': {'title': {'text': 'Number of Reads'}},\n",
       "                              'colorscale': [[0.0, '#0d0887'], [0.1111111111111111,\n",
       "                                             '#46039f'], [0.2222222222222222,\n",
       "                                             '#7201a8'], [0.3333333333333333,\n",
       "                                             '#9c179e'], [0.4444444444444444,\n",
       "                                             '#bd3786'], [0.5555555555555556,\n",
       "                                             '#d8576b'], [0.6666666666666666,\n",
       "                                             '#ed7953'], [0.7777777777777778,\n",
       "                                             '#fb9f3a'], [0.8888888888888888,\n",
       "                                             '#fdca26'], [1.0, '#f0f921']]},\n",
       "                'height': 700,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'template': '...',\n",
       "                'title': {'text': ' Top 20 Firms by Readership'},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 1.0], 'title': {'text': 'Number of Reads'}},\n",
       "                'yaxis': {'anchor': 'x',\n",
       "                          'categoryorder': 'total ascending',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'title': {'text': 'Firm name'}}}\n",
       " }),\n",
       " 'asset_class': Figure({\n",
       "     'data': [{'domain': {'x': [0.0, 1.0], 'y': [0.0, 1.0]},\n",
       "               'hole': 0.4,\n",
       "               'hovertemplate': 'Asset_Class=%{label}<br>Reads=%{value}<extra></extra>',\n",
       "               'labels': array(['Equity', 'FixedIncome', 'Currency', 'Commodity'], dtype=object),\n",
       "               'legendgroup': '',\n",
       "               'name': '',\n",
       "               'showlegend': True,\n",
       "               'textinfo': 'percent+label',\n",
       "               'textposition': 'inside',\n",
       "               'type': 'pie',\n",
       "               'values': {'bdata': 'NhHvArYBswA=', 'dtype': 'i2'}}],\n",
       "     'layout': {'height': 500,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'template': '...',\n",
       "                'title': {'text': ' Asset Class Distribution'}}\n",
       " }),\n",
       " 'content_chars': Figure({\n",
       "     'data': [{'marker': {'color': 'indianred'},\n",
       "               'type': 'bar',\n",
       "               'x': array(['Fundamental'], dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': {'bdata': 'fxU=', 'dtype': 'i2'},\n",
       "               'yaxis': 'y'},\n",
       "              {'marker': {'color': 'lightsalmon'},\n",
       "               'type': 'bar',\n",
       "               'x': array(['Action', 'Education', 'Influence'], dtype=object),\n",
       "               'xaxis': 'x2',\n",
       "               'y': {'bdata': 'ZQIfABIA', 'dtype': 'i2'},\n",
       "               'yaxis': 'y2'}],\n",
       "     'layout': {'annotations': [{'font': {'size': 16},\n",
       "                                 'showarrow': False,\n",
       "                                 'text': '🔬 Research Approach',\n",
       "                                 'x': 0.225,\n",
       "                                 'xanchor': 'center',\n",
       "                                 'xref': 'paper',\n",
       "                                 'y': 1.0,\n",
       "                                 'yanchor': 'bottom',\n",
       "                                 'yref': 'paper'},\n",
       "                                {'font': {'size': 16},\n",
       "                                 'showarrow': False,\n",
       "                                 'text': '📋 Report Purpose',\n",
       "                                 'x': 0.775,\n",
       "                                 'xanchor': 'center',\n",
       "                                 'xref': 'paper',\n",
       "                                 'y': 1.0,\n",
       "                                 'yanchor': 'bottom',\n",
       "                                 'yref': 'paper'}],\n",
       "                'height': 500,\n",
       "                'showlegend': False,\n",
       "                'template': '...',\n",
       "                'title': {'text': '📊 Content Characteristics'},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.45]},\n",
       "                'xaxis2': {'anchor': 'y2', 'domain': [0.55, 1.0]},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0]},\n",
       "                'yaxis2': {'anchor': 'x2', 'domain': [0.0, 1.0]}}\n",
       " })}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7703f31",
   "metadata": {},
   "source": [
    "### STATISTICAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9723ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis(df):\n",
    "    \"\"\"Perform statistical tests and analysis\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTICAL ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60fb3499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chi-Square Test: Region vs Asset Class\n",
      "   • Chi-square statistic: 119.7631\n",
      "   • P-value: 0.0000\n",
      "   • Degrees of freedom: 15\n",
      "   • Result: Significant relationship (p < 0.05)\n"
     ]
    }
   ],
   "source": [
    "# Chi-square test: Region vs Asset Class\n",
    "if 'Region' in df.columns and 'Asset Class' in df.columns:\n",
    "    contingency = pd.crosstab(df['Region'], df['Asset Class'])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "    print(\"\\n Chi-Square Test: Region vs Asset Class\")\n",
    "    print(f\"   • Chi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"   • P-value: {p_value:.4f}\")\n",
    "    print(f\"   • Degrees of freedom: {dof}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"   • Result: Significant relationship (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"   • Result: No significant relationship (p >= 0.05)\")\n",
    "    results['chi_square'] = {'chi2': chi2, 'p_value': p_value, 'dof': dof}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "576a62ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Correlation Matrix:\n",
      "                                        Year  Parent Firm ID (FactSet)  \\\n",
      "Year                                1.000000                  0.038838   \n",
      "Parent Firm ID (FactSet)            0.038838                  1.000000   \n",
      "Firm ID (FactSet)                   0.321610                  0.523488   \n",
      "Primary analyst code (contributor)  0.816831                  0.047761   \n",
      "Primary analyst code (FactSet)      0.871148                  0.045808   \n",
      "Number of pages in report           0.254218                  0.028565   \n",
      "Primary Industry Code (FactSet)     0.037983                 -0.036769   \n",
      "\n",
      "                                    Firm ID (FactSet)  \\\n",
      "Year                                         0.321610   \n",
      "Parent Firm ID (FactSet)                     0.523488   \n",
      "Firm ID (FactSet)                            1.000000   \n",
      "Primary analyst code (contributor)           0.323662   \n",
      "Primary analyst code (FactSet)               0.333560   \n",
      "Number of pages in report                    0.080222   \n",
      "Primary Industry Code (FactSet)             -0.053906   \n",
      "\n",
      "                                    Primary analyst code (contributor)  \\\n",
      "Year                                                          0.816831   \n",
      "Parent Firm ID (FactSet)                                      0.047761   \n",
      "Firm ID (FactSet)                                             0.323662   \n",
      "Primary analyst code (contributor)                            1.000000   \n",
      "Primary analyst code (FactSet)                                0.945426   \n",
      "Number of pages in report                                     0.212376   \n",
      "Primary Industry Code (FactSet)                              -0.053387   \n",
      "\n",
      "                                    Primary analyst code (FactSet)  \\\n",
      "Year                                                      0.871148   \n",
      "Parent Firm ID (FactSet)                                  0.045808   \n",
      "Firm ID (FactSet)                                         0.333560   \n",
      "Primary analyst code (contributor)                        0.945426   \n",
      "Primary analyst code (FactSet)                            1.000000   \n",
      "Number of pages in report                                 0.231362   \n",
      "Primary Industry Code (FactSet)                          -0.020223   \n",
      "\n",
      "                                    Number of pages in report  \\\n",
      "Year                                                 0.254218   \n",
      "Parent Firm ID (FactSet)                             0.028565   \n",
      "Firm ID (FactSet)                                    0.080222   \n",
      "Primary analyst code (contributor)                   0.212376   \n",
      "Primary analyst code (FactSet)                       0.231362   \n",
      "Number of pages in report                            1.000000   \n",
      "Primary Industry Code (FactSet)                      0.224253   \n",
      "\n",
      "                                    Primary Industry Code (FactSet)  \n",
      "Year                                                       0.037983  \n",
      "Parent Firm ID (FactSet)                                  -0.036769  \n",
      "Firm ID (FactSet)                                         -0.053906  \n",
      "Primary analyst code (contributor)                        -0.053387  \n",
      "Primary analyst code (FactSet)                            -0.020223  \n",
      "Number of pages in report                                  0.224253  \n",
      "Primary Industry Code (FactSet)                            1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 1:\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    print(\"\\n Correlation Matrix:\")\n",
    "    print(corr_matrix)\n",
    "    results['correlation'] = corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2cfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
