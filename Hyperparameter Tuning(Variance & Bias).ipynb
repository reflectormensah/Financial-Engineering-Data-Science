{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reflectormensah/Financial-Engineering-Data-Science/blob/main/Hyperparameter%20Tuning(Variance%20%26%20Bias).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing the Trade off between variance and bias"
      ],
      "metadata": {
        "id": "yAXQ2-i55glP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc89b6QN4sA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd00258-7f5f-47ee-ce61-db1e4a2c1e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.2-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.2\n",
            "{'uci_id': 27, 'name': 'Credit Approval', 'repository_url': 'https://archive.ics.uci.edu/dataset/27/credit+approval', 'data_url': 'https://archive.ics.uci.edu/static/public/27/data.csv', 'abstract': 'This data concerns credit card applications; good mix of attributes', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 690, 'num_features': 15, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['A16'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1987, 'last_updated': 'Wed Aug 23 2023', 'dataset_doi': '10.24432/C5FS30', 'creators': ['J. R. Quinlan'], 'intro_paper': None, 'additional_info': {'summary': 'This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.\\r\\n  \\r\\nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'A1:\\tb, a.\\r\\nA2:\\tcontinuous.\\r\\nA3:\\tcontinuous.\\r\\nA4:\\tu, y, l, t.\\r\\nA5:\\tg, p, gg.\\r\\nA6:\\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\\r\\nA7:\\tv, h, bb, j, n, z, dd, ff, o.\\r\\nA8:\\tcontinuous.\\r\\nA9:\\tt, f.\\r\\nA10:\\tt, f.\\r\\nA11:\\tcontinuous.\\r\\nA12:\\tt, f.\\r\\nA13:\\tg, p, s.\\r\\nA14:\\tcontinuous.\\r\\nA15:\\tcontinuous.\\r\\nA16: +,-         (class attribute)', 'citation': None}}\n",
            "   name     role         type demographic description units missing_values\n",
            "0   A16   Target  Categorical        None        None  None             no\n",
            "1   A15  Feature   Continuous        None        None  None             no\n",
            "2   A14  Feature   Continuous        None        None  None            yes\n",
            "3   A13  Feature  Categorical        None        None  None             no\n",
            "4   A12  Feature  Categorical        None        None  None             no\n",
            "5   A11  Feature   Continuous        None        None  None             no\n",
            "6   A10  Feature  Categorical        None        None  None             no\n",
            "7    A9  Feature  Categorical        None        None  None             no\n",
            "8    A8  Feature   Continuous        None        None  None             no\n",
            "9    A7  Feature  Categorical        None        None  None            yes\n",
            "10   A6  Feature  Categorical        None        None  None            yes\n",
            "11   A5  Feature  Categorical        None        None  None            yes\n",
            "12   A4  Feature  Categorical        None        None  None            yes\n",
            "13   A3  Feature   Continuous        None        None  None             no\n",
            "14   A2  Feature   Continuous        None        None  None            yes\n",
            "15   A1  Feature  Categorical        None        None  None            yes\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "# This data concerns credit card applications; good mix of attributes\n",
        "credit_approval = fetch_ucirepo(id=27)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = credit_approval.data.features\n",
        "y = credit_approval.data.targets\n",
        "\n",
        "# metadata\n",
        "print(credit_approval.metadata)\n",
        "\n",
        "# variable information\n",
        "print(credit_approval.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the feature names are hidden since this type of data is considered personal data for the purpose of the example we can use this data\n",
        "X.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CCdiAjcvs80C",
        "outputId": "88302b8b-0475-48f3-a40a-3eacbf233ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   A15    A14 A13 A12  A11 A10 A9    A8 A7 A6 A5 A4     A3     A2 A1\n",
              "0    0  202.0   g   f    1   t  t  1.25  v  w  g  u  0.000  30.83  b\n",
              "1  560   43.0   g   f    6   t  t  3.04  h  q  g  u  4.460  58.67  a\n",
              "2  824  280.0   g   f    0   f  t  1.50  h  q  g  u  0.500  24.50  a\n",
              "3    3  100.0   g   t    5   t  t  3.75  v  w  g  u  1.540  27.83  b\n",
              "4    0  120.0   s   f    0   f  t  1.71  v  w  g  u  5.625  20.17  b"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-371948f1-8a73-4b02-95b9-c635661a6bf3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A15</th>\n",
              "      <th>A14</th>\n",
              "      <th>A13</th>\n",
              "      <th>A12</th>\n",
              "      <th>A11</th>\n",
              "      <th>A10</th>\n",
              "      <th>A9</th>\n",
              "      <th>A8</th>\n",
              "      <th>A7</th>\n",
              "      <th>A6</th>\n",
              "      <th>A5</th>\n",
              "      <th>A4</th>\n",
              "      <th>A3</th>\n",
              "      <th>A2</th>\n",
              "      <th>A1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>1</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1.25</td>\n",
              "      <td>v</td>\n",
              "      <td>w</td>\n",
              "      <td>g</td>\n",
              "      <td>u</td>\n",
              "      <td>0.000</td>\n",
              "      <td>30.83</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>560</td>\n",
              "      <td>43.0</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>6</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>3.04</td>\n",
              "      <td>h</td>\n",
              "      <td>q</td>\n",
              "      <td>g</td>\n",
              "      <td>u</td>\n",
              "      <td>4.460</td>\n",
              "      <td>58.67</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>824</td>\n",
              "      <td>280.0</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1.50</td>\n",
              "      <td>h</td>\n",
              "      <td>q</td>\n",
              "      <td>g</td>\n",
              "      <td>u</td>\n",
              "      <td>0.500</td>\n",
              "      <td>24.50</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>g</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>3.75</td>\n",
              "      <td>v</td>\n",
              "      <td>w</td>\n",
              "      <td>g</td>\n",
              "      <td>u</td>\n",
              "      <td>1.540</td>\n",
              "      <td>27.83</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>s</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1.71</td>\n",
              "      <td>v</td>\n",
              "      <td>w</td>\n",
              "      <td>g</td>\n",
              "      <td>u</td>\n",
              "      <td>5.625</td>\n",
              "      <td>20.17</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-371948f1-8a73-4b02-95b9-c635661a6bf3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-371948f1-8a73-4b02-95b9-c635661a6bf3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-371948f1-8a73-4b02-95b9-c635661a6bf3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb538a01-150e-424e-9ed4-1bba1842f411\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb538a01-150e-424e-9ed4-1bba1842f411')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb538a01-150e-424e-9ed4-1bba1842f411 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm7M4Sq1-wDl",
        "outputId": "ca830a7f-1ecc-441b-c115-570236a90796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 15 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A15     690 non-null    int64  \n",
            " 1   A14     677 non-null    float64\n",
            " 2   A13     690 non-null    object \n",
            " 3   A12     690 non-null    object \n",
            " 4   A11     690 non-null    int64  \n",
            " 5   A10     690 non-null    object \n",
            " 6   A9      690 non-null    object \n",
            " 7   A8      690 non-null    float64\n",
            " 8   A7      681 non-null    object \n",
            " 9   A6      681 non-null    object \n",
            " 10  A5      684 non-null    object \n",
            " 11  A4      684 non-null    object \n",
            " 12  A3      690 non-null    float64\n",
            " 13  A2      678 non-null    float64\n",
            " 14  A1      678 non-null    object \n",
            "dtypes: float64(4), int64(2), object(9)\n",
            "memory usage: 81.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.fillna(method='ffill' , inplace=True)\n",
        "X.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inJlwL5ymQmk",
        "outputId": "365903e8-7ecf-4499-a83a-fcf3da64a1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-7187959ac096>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(method='ffill' , inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A15    0\n",
              "A14    0\n",
              "A13    0\n",
              "A12    0\n",
              "A11    0\n",
              "A10    0\n",
              "A9     0\n",
              "A8     0\n",
              "A7     0\n",
              "A6     0\n",
              "A5     0\n",
              "A4     0\n",
              "A3     0\n",
              "A2     0\n",
              "A1     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "hiLImIaG0-7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_selector as selector\n",
        "\n",
        "categorical_columns_selector = selector(dtype_include=object)\n",
        "categorical_columns = categorical_columns_selector(X)\n",
        "categorical_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6bVGw2OhXSi",
        "outputId": "108d97b9-c3a4-4aa3-c077-d4d2c8d21a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A13', 'A12', 'A10', 'A9', 'A7', 'A6', 'A5', 'A4', 'A1']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's identify the numerical variables\n",
        "\n",
        "num_vars = [var for var in X.columns if var not in categorical_columns]\n",
        "\n",
        "# number of numerical variables\n",
        "print(len(num_vars))\n",
        "print(num_vars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF9OY60uhxzG",
        "outputId": "1eb43a15-9a03-40de-a041-442ad733d006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "['A15', 'A14', 'A11', 'A8', 'A3', 'A2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "numerical_preprocessor = StandardScaler()"
      ],
      "metadata": {
        "id": "WZldfHLMh81l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"one-hot-encoder\", categorical_preprocessor, categorical_columns),\n",
        "        (\"standard_scaler\", numerical_preprocessor, num_vars),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "GpTNW0gTiml_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline(\n",
        "    [\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"regressor\", RandomForestClassifier(random_state=42)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "CJNXvPwQi8al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import set_config\n",
        "\n",
        "set_config(display=\"diagram\")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "IlitDeY8jCUt",
        "outputId": "71c12616-9635-48d6-8a54-30841b2fae02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                  ['A13', 'A12', 'A10', 'A9',\n",
              "                                                   'A7', 'A6', 'A5', 'A4',\n",
              "                                                   'A1']),\n",
              "                                                 ('standard_scaler',\n",
              "                                                  StandardScaler(),\n",
              "                                                  ['A15', 'A14', 'A11', 'A8',\n",
              "                                                   'A3', 'A2'])])),\n",
              "                ('regressor', RandomForestClassifier(random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;,\n",
              "                                                   &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;,\n",
              "                                                   &#x27;A1&#x27;]),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;,\n",
              "                                                   &#x27;A3&#x27;, &#x27;A2&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;,\n",
              "                                                   &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;,\n",
              "                                                   &#x27;A1&#x27;]),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;,\n",
              "                                                   &#x27;A3&#x27;, &#x27;A2&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;, &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;,\n",
              "                                  &#x27;A4&#x27;, &#x27;A1&#x27;]),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;, &#x27;A3&#x27;, &#x27;A2&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;, &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;, &#x27;A1&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;, &#x27;A3&#x27;, &#x27;A2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2J_DnjsEnNFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = y.copy()\n",
        "y_new[y_new =='+'] = '1'\n",
        "y_new[y_new =='-'] = '0'\n",
        "y_new\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,  # predictive variables\n",
        "    y_new,  # target\n",
        "    test_size=0.3,  # portion of dataset to allocate to test set\n",
        "    random_state=0,  # we are setting the seed here\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dak8R4ZajCZH",
        "outputId": "150730b3-007f-439b-ccff-b2a39230a6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((483, 15), (207, 15))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "sbCGlh2ojCdJ",
        "outputId": "8947688c-22ae-4c36-ac25-9a34ceda9d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                  ['A13', 'A12', 'A10', 'A9',\n",
              "                                                   'A7', 'A6', 'A5', 'A4',\n",
              "                                                   'A1']),\n",
              "                                                 ('standard_scaler',\n",
              "                                                  StandardScaler(),\n",
              "                                                  ['A15', 'A14', 'A11', 'A8',\n",
              "                                                   'A3', 'A2'])])),\n",
              "                ('regressor', RandomForestClassifier(random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;,\n",
              "                                                   &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;,\n",
              "                                                   &#x27;A1&#x27;]),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;,\n",
              "                                                   &#x27;A3&#x27;, &#x27;A2&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;,\n",
              "                                                   &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;,\n",
              "                                                   &#x27;A1&#x27;]),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;,\n",
              "                                                   &#x27;A3&#x27;, &#x27;A2&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;, &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;,\n",
              "                                  &#x27;A4&#x27;, &#x27;A1&#x27;]),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;, &#x27;A3&#x27;, &#x27;A2&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;, &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;, &#x27;A1&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;, &#x27;A3&#x27;, &#x27;A2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "target_predicted = model.predict(X_test)\n",
        "\n",
        "print(\n",
        "    f\"accuracy score on the testing set: \"\n",
        "    f\"{accuracy_score(y_test, target_predicted):.3f}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJWAlInQk-1",
        "outputId": "6d629810-2975-4969-906e-b269707113b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score on the testing set: 0.865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Look at parameters used by our current forest\n",
        "print(\"Parameters currently in use:\\n\")\n",
        "pprint(model.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI2Jz8n91AnZ",
        "outputId": "a0b73dbb-2be0-49c2-d380-6ed62e7fcd96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'memory': None,\n",
            " 'preprocessor': ColumnTransformer(transformers=[('one-hot-encoder',\n",
            "                                 OneHotEncoder(handle_unknown='ignore'),\n",
            "                                 ['A13', 'A12', 'A10', 'A9', 'A7', 'A6', 'A5',\n",
            "                                  'A4', 'A1']),\n",
            "                                ('standard_scaler', StandardScaler(),\n",
            "                                 ['A15', 'A14', 'A11', 'A8', 'A3', 'A2'])]),\n",
            " 'preprocessor__n_jobs': None,\n",
            " 'preprocessor__one-hot-encoder': OneHotEncoder(handle_unknown='ignore'),\n",
            " 'preprocessor__one-hot-encoder__categories': 'auto',\n",
            " 'preprocessor__one-hot-encoder__drop': None,\n",
            " 'preprocessor__one-hot-encoder__dtype': <class 'numpy.float64'>,\n",
            " 'preprocessor__one-hot-encoder__handle_unknown': 'ignore',\n",
            " 'preprocessor__one-hot-encoder__max_categories': None,\n",
            " 'preprocessor__one-hot-encoder__min_frequency': None,\n",
            " 'preprocessor__one-hot-encoder__sparse': 'deprecated',\n",
            " 'preprocessor__one-hot-encoder__sparse_output': True,\n",
            " 'preprocessor__remainder': 'drop',\n",
            " 'preprocessor__sparse_threshold': 0.3,\n",
            " 'preprocessor__standard_scaler': StandardScaler(),\n",
            " 'preprocessor__standard_scaler__copy': True,\n",
            " 'preprocessor__standard_scaler__with_mean': True,\n",
            " 'preprocessor__standard_scaler__with_std': True,\n",
            " 'preprocessor__transformer_weights': None,\n",
            " 'preprocessor__transformers': [('one-hot-encoder',\n",
            "                                 OneHotEncoder(handle_unknown='ignore'),\n",
            "                                 ['A13',\n",
            "                                  'A12',\n",
            "                                  'A10',\n",
            "                                  'A9',\n",
            "                                  'A7',\n",
            "                                  'A6',\n",
            "                                  'A5',\n",
            "                                  'A4',\n",
            "                                  'A1']),\n",
            "                                ('standard_scaler',\n",
            "                                 StandardScaler(),\n",
            "                                 ['A15', 'A14', 'A11', 'A8', 'A3', 'A2'])],\n",
            " 'preprocessor__verbose': False,\n",
            " 'preprocessor__verbose_feature_names_out': True,\n",
            " 'regressor': RandomForestClassifier(random_state=42),\n",
            " 'regressor__bootstrap': True,\n",
            " 'regressor__ccp_alpha': 0.0,\n",
            " 'regressor__class_weight': None,\n",
            " 'regressor__criterion': 'gini',\n",
            " 'regressor__max_depth': None,\n",
            " 'regressor__max_features': 'sqrt',\n",
            " 'regressor__max_leaf_nodes': None,\n",
            " 'regressor__max_samples': None,\n",
            " 'regressor__min_impurity_decrease': 0.0,\n",
            " 'regressor__min_samples_leaf': 1,\n",
            " 'regressor__min_samples_split': 2,\n",
            " 'regressor__min_weight_fraction_leaf': 0.0,\n",
            " 'regressor__n_estimators': 100,\n",
            " 'regressor__n_jobs': None,\n",
            " 'regressor__oob_score': False,\n",
            " 'regressor__random_state': 42,\n",
            " 'regressor__verbose': 0,\n",
            " 'regressor__warm_start': False,\n",
            " 'steps': [('preprocessor',\n",
            "            ColumnTransformer(transformers=[('one-hot-encoder',\n",
            "                                 OneHotEncoder(handle_unknown='ignore'),\n",
            "                                 ['A13', 'A12', 'A10', 'A9', 'A7', 'A6', 'A5',\n",
            "                                  'A4', 'A1']),\n",
            "                                ('standard_scaler', StandardScaler(),\n",
            "                                 ['A15', 'A14', 'A11', 'A8', 'A3', 'A2'])])),\n",
            "           ('regressor', RandomForestClassifier(random_state=42))],\n",
            " 'verbose': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start=5, stop=50, num=10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = [\"auto\", \"sqrt\"]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 20, num=21)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 7]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {\n",
        "    \"regressor__n_estimators\": n_estimators,\n",
        "    \"regressor__max_features\": max_features,\n",
        "    \"regressor__max_depth\": max_depth,\n",
        "    \"regressor__min_samples_split\": min_samples_split,\n",
        "    \"regressor__min_samples_leaf\": min_samples_leaf,\n",
        "    \"regressor__bootstrap\": bootstrap,\n",
        "}\n",
        "pprint(random_grid)"
      ],
      "metadata": {
        "id": "-xEdgatn1Aq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f3f611-c95a-4b59-dccc-782c3057385b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'regressor__bootstrap': [True, False],\n",
            " 'regressor__max_depth': [5,\n",
            "                          5,\n",
            "                          6,\n",
            "                          7,\n",
            "                          8,\n",
            "                          8,\n",
            "                          9,\n",
            "                          10,\n",
            "                          11,\n",
            "                          11,\n",
            "                          12,\n",
            "                          13,\n",
            "                          14,\n",
            "                          14,\n",
            "                          15,\n",
            "                          16,\n",
            "                          17,\n",
            "                          17,\n",
            "                          18,\n",
            "                          19,\n",
            "                          20,\n",
            "                          None],\n",
            " 'regressor__max_features': ['auto', 'sqrt'],\n",
            " 'regressor__min_samples_leaf': [1, 2, 4],\n",
            " 'regressor__min_samples_split': [2, 5, 7],\n",
            " 'regressor__n_estimators': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=random_grid,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        ")\n",
        "model_random_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4joJaVnZ1AuP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33debe21-e422-46d0-9f17-0c5bddabd9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('preprocessor',\n",
              "                                              ColumnTransformer(transformers=[('one-hot-encoder',\n",
              "                                                                               OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                                               ['A13',\n",
              "                                                                                'A12',\n",
              "                                                                                'A10',\n",
              "                                                                                'A9',\n",
              "                                                                                'A7',\n",
              "                                                                                'A6',\n",
              "                                                                                'A5',\n",
              "                                                                                'A4',\n",
              "                                                                                'A1']),\n",
              "                                                                              ('standard_scaler',\n",
              "                                                                               StandardScaler(),\n",
              "                                                                               ['A15',\n",
              "                                                                                'A14',\n",
              "                                                                                'A11',\n",
              "                                                                                'A8',\n",
              "                                                                                'A3',\n",
              "                                                                                'A2'])])),\n",
              "                                             ('regressor',\n",
              "                                              RandomForestClassifier(random_state=42))]),\n",
              "                   param_distributions={'regressor__bootstrap': [True, False],\n",
              "                                        'regressor__max_depth': [5, 5, 6, 7, 8,\n",
              "                                                                 8, 9, 10, 11,\n",
              "                                                                 11, 12, 13, 14,\n",
              "                                                                 14, 15, 16, 17,\n",
              "                                                                 17, 18, 19, 20,\n",
              "                                                                 None],\n",
              "                                        'regressor__max_features': ['auto',\n",
              "                                                                    'sqrt'],\n",
              "                                        'regressor__min_samples_leaf': [1, 2,\n",
              "                                                                        4],\n",
              "                                        'regressor__min_samples_split': [2, 5,\n",
              "                                                                         7],\n",
              "                                        'regressor__n_estimators': [5, 10, 15,\n",
              "                                                                    20, 25, 30,\n",
              "                                                                    35, 40, 45,\n",
              "                                                                    50]},\n",
              "                   verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                                              ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                                               OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                                               [&#x27;A13&#x27;,\n",
              "                                                                                &#x27;A12&#x27;,\n",
              "                                                                                &#x27;A10&#x27;,\n",
              "                                                                                &#x27;A9&#x27;,\n",
              "                                                                                &#x27;A7&#x27;,\n",
              "                                                                                &#x27;A6&#x27;,\n",
              "                                                                                &#x27;A5&#x27;,\n",
              "                                                                                &#x27;A4&#x27;,\n",
              "                                                                                &#x27;A1&#x27;]),\n",
              "                                                                              (&#x27;standard_scaler&#x27;,\n",
              "                                                                               StandardScaler(),\n",
              "                                                                               [&#x27;A15&#x27;,\n",
              "                                                                                &#x27;A14&#x27;,\n",
              "                                                                                &#x27;A11&#x27;,\n",
              "                                                                                &#x27;A8&#x27;,\n",
              "                                                                                &#x27;A3&#x27;,\n",
              "                                                                                &#x27;A2&#x27;])])),\n",
              "                                             (&#x27;regressor&#x27;,\n",
              "                                              RandomForestClassifier(random_state=42))]),\n",
              "                   param_distributions={&#x27;regressor__bootstrap&#x27;: [True, False],\n",
              "                                        &#x27;regressor__max_depth&#x27;: [5, 5, 6, 7, 8,\n",
              "                                                                 8, 9, 10, 11,\n",
              "                                                                 11, 12, 13, 14,\n",
              "                                                                 14, 15, 16, 17,\n",
              "                                                                 17, 18, 19, 20,\n",
              "                                                                 None],\n",
              "                                        &#x27;regressor__max_features&#x27;: [&#x27;auto&#x27;,\n",
              "                                                                    &#x27;sqrt&#x27;],\n",
              "                                        &#x27;regressor__min_samples_leaf&#x27;: [1, 2,\n",
              "                                                                        4],\n",
              "                                        &#x27;regressor__min_samples_split&#x27;: [2, 5,\n",
              "                                                                         7],\n",
              "                                        &#x27;regressor__n_estimators&#x27;: [5, 10, 15,\n",
              "                                                                    20, 25, 30,\n",
              "                                                                    35, 40, 45,\n",
              "                                                                    50]},\n",
              "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                                              ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                                               OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                                               [&#x27;A13&#x27;,\n",
              "                                                                                &#x27;A12&#x27;,\n",
              "                                                                                &#x27;A10&#x27;,\n",
              "                                                                                &#x27;A9&#x27;,\n",
              "                                                                                &#x27;A7&#x27;,\n",
              "                                                                                &#x27;A6&#x27;,\n",
              "                                                                                &#x27;A5&#x27;,\n",
              "                                                                                &#x27;A4&#x27;,\n",
              "                                                                                &#x27;A1&#x27;]),\n",
              "                                                                              (&#x27;standard_scaler&#x27;,\n",
              "                                                                               StandardScaler(),\n",
              "                                                                               [&#x27;A15&#x27;,\n",
              "                                                                                &#x27;A14&#x27;,\n",
              "                                                                                &#x27;A11&#x27;,\n",
              "                                                                                &#x27;A8&#x27;,\n",
              "                                                                                &#x27;A3&#x27;,\n",
              "                                                                                &#x27;A2&#x27;])])),\n",
              "                                             (&#x27;regressor&#x27;,\n",
              "                                              RandomForestClassifier(random_state=42))]),\n",
              "                   param_distributions={&#x27;regressor__bootstrap&#x27;: [True, False],\n",
              "                                        &#x27;regressor__max_depth&#x27;: [5, 5, 6, 7, 8,\n",
              "                                                                 8, 9, 10, 11,\n",
              "                                                                 11, 12, 13, 14,\n",
              "                                                                 14, 15, 16, 17,\n",
              "                                                                 17, 18, 19, 20,\n",
              "                                                                 None],\n",
              "                                        &#x27;regressor__max_features&#x27;: [&#x27;auto&#x27;,\n",
              "                                                                    &#x27;sqrt&#x27;],\n",
              "                                        &#x27;regressor__min_samples_leaf&#x27;: [1, 2,\n",
              "                                                                        4],\n",
              "                                        &#x27;regressor__min_samples_split&#x27;: [2, 5,\n",
              "                                                                         7],\n",
              "                                        &#x27;regressor__n_estimators&#x27;: [5, 10, 15,\n",
              "                                                                    20, 25, 30,\n",
              "                                                                    35, 40, 45,\n",
              "                                                                    50]},\n",
              "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;,\n",
              "                                                   &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;,\n",
              "                                                   &#x27;A1&#x27;]),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;,\n",
              "                                                   &#x27;A3&#x27;, &#x27;A2&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;, &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;,\n",
              "                                  &#x27;A4&#x27;, &#x27;A1&#x27;]),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 [&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;, &#x27;A3&#x27;, &#x27;A2&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A13&#x27;, &#x27;A12&#x27;, &#x27;A10&#x27;, &#x27;A9&#x27;, &#x27;A7&#x27;, &#x27;A6&#x27;, &#x27;A5&#x27;, &#x27;A4&#x27;, &#x27;A1&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A15&#x27;, &#x27;A14&#x27;, &#x27;A11&#x27;, &#x27;A8&#x27;, &#x27;A3&#x27;, &#x27;A2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_random_search.best_params_"
      ],
      "metadata": {
        "id": "N2K_V08X1AyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c41c04-cab4-46e8-f5dd-91bf9c9aa615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'regressor__n_estimators': 50,\n",
              " 'regressor__min_samples_split': 2,\n",
              " 'regressor__min_samples_leaf': 2,\n",
              " 'regressor__max_features': 'auto',\n",
              " 'regressor__max_depth': 17,\n",
              " 'regressor__bootstrap': True}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "    print(\"Model Performance\")\n",
        "    print(\"Accuracy = {:0.2f}.\".format(accuracy))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "base_model = model\n",
        "base_model.fit(X_train, y_train)\n",
        "base_accuracy = evaluate(base_model, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyb7LAs22pG4",
        "outputId": "6697018c-77f4-4e02-b5d9-f0bd9bfe572f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Accuracy = 0.86.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_random = model_random_search.best_estimator_\n",
        "random_accuracy = evaluate(best_random, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcu9WI9T2pKn",
        "outputId": "bd47117d-00f5-4734-c827-e7e0da55e242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Accuracy = 0.86.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search\n",
        "param_grid = {\n",
        "    \"regressor__bootstrap\": [True],\n",
        "    \"regressor__max_depth\": [int(x) for x in np.linspace(2, 10, num=6)],\n",
        "    \"regressor__max_features\": [2, 3],\n",
        "    \"regressor__min_samples_leaf\": [3, 4, 5],\n",
        "    \"regressor__min_samples_split\": [8, 10, 12],\n",
        "    \"regressor__n_estimators\": [\n",
        "        int(x) for x in np.linspace(start=10, stop=50, num=11)\n",
        "    ],\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "939fHGJK2pOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeOw-mQY5Nh8",
        "outputId": "4ac2ee44-5dce-49a0-d9da-7a7c20cad868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1188 candidates, totalling 3564 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'regressor__bootstrap': True,\n",
              " 'regressor__max_depth': 10,\n",
              " 'regressor__max_features': 3,\n",
              " 'regressor__min_samples_leaf': 3,\n",
              " 'regressor__min_samples_split': 8,\n",
              " 'regressor__n_estimators': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_random = grid_search.best_estimator_\n",
        "random_accuracy = evaluate(best_random, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy-K2WsC5NlN",
        "outputId": "57bf4618-ba54-4c8c-ee27-da5564a7acbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Accuracy = 0.87.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Hyperparameter** **Optimzation**"
      ],
      "metadata": {
        "id": "VDC41pox4CMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the necessary libraries and data"
      ],
      "metadata": {
        "id": "JsDJz8PQ5luR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the sonar dataset\n",
        "from pandas import read_csv\n",
        "\n",
        "# grid search logistic regression model on the sonar dataset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# random search logistic regression model on the sonar dataset\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
        "dataframe = read_csv(url, header=None)\n",
        "\n",
        "# define model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KNPeek14TNX",
        "outputId": "657e5589-4ff2-4e86-ad04-f28a688af93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 60) (208,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Performing a Randomized Search Optimization"
      ],
      "metadata": {
        "id": "Blf4TsgK83eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = read_csv(url, header=None)\n",
        "\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
        "space['C'] = loguniform(1e-5, 100)\n",
        "\n",
        "# define search\n",
        "search = RandomizedSearchCV(model, space, n_iter=600, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "# summarize result\n",
        "print('Best Score: %s' % result.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0yMFb5M82ik",
        "outputId": "274d0f56-9462-49d1-a689-2f93e9dd65bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7897619047619049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "8490 fits failed out of a total of 18000.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1680 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1440 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1140 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1500 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1470 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1260 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.72746032        nan 0.73071429        nan 0.54984127 0.56769841\n",
            " 0.53380952 0.53380952        nan        nan        nan        nan\n",
            " 0.72746032        nan 0.76730159        nan        nan 0.73071429\n",
            " 0.53380952        nan 0.78007937 0.53380952 0.73071429 0.53380952\n",
            " 0.76269841        nan 0.72746032        nan 0.72746032 0.7815873\n",
            " 0.53380952        nan 0.72746032        nan 0.72746032 0.77666667\n",
            "        nan 0.72746032 0.53380952        nan 0.67634921 0.77698413\n",
            " 0.53380952 0.53539683        nan 0.53380952        nan        nan\n",
            "        nan        nan        nan 0.72746032        nan 0.73071429\n",
            "        nan 0.73071429        nan        nan        nan        nan\n",
            " 0.76119048        nan 0.78126984 0.57888889        nan 0.53698413\n",
            "        nan 0.76380952 0.72746032 0.53380952        nan        nan\n",
            "        nan        nan 0.72746032 0.76896825        nan 0.60293651\n",
            " 0.53380952 0.72746032        nan 0.78       0.53380952        nan\n",
            " 0.53380952        nan 0.72746032 0.53380952        nan        nan\n",
            " 0.53380952        nan        nan 0.74611111        nan        nan\n",
            "        nan        nan 0.53380952        nan        nan        nan\n",
            "        nan 0.53380952 0.70142857        nan 0.68246032        nan\n",
            " 0.53380952 0.58547619        nan        nan 0.70309524        nan\n",
            " 0.73071429 0.75150794 0.73071429        nan        nan 0.72746032\n",
            " 0.75166667 0.77634921 0.73071429        nan 0.53380952 0.53380952\n",
            "        nan        nan 0.53380952        nan 0.53380952 0.7768254\n",
            " 0.78492063 0.53380952 0.53380952 0.73071429        nan 0.75960317\n",
            " 0.77214286        nan 0.53380952        nan 0.74825397        nan\n",
            " 0.53380952 0.72746032 0.73071429 0.72746032 0.53380952        nan\n",
            " 0.73071429 0.53380952 0.53380952 0.72746032        nan        nan\n",
            "        nan        nan 0.7768254  0.53380952 0.78126984        nan\n",
            "        nan        nan        nan 0.67293651        nan        nan\n",
            " 0.73071429 0.75968254 0.68246032        nan        nan 0.77507937\n",
            " 0.53380952        nan        nan 0.53380952        nan 0.73071429\n",
            " 0.77650794        nan 0.53380952        nan 0.72746032 0.53380952\n",
            " 0.76111111        nan        nan        nan 0.73071429 0.53380952\n",
            " 0.76365079 0.71261905 0.73071429 0.53380952        nan        nan\n",
            " 0.73071429        nan        nan 0.53380952 0.73071429 0.53380952\n",
            "        nan        nan        nan 0.7747619  0.7752381  0.76269841\n",
            "        nan 0.7897619  0.73071429        nan        nan 0.73071429\n",
            " 0.53698413        nan        nan        nan 0.53380952        nan\n",
            " 0.73071429        nan        nan        nan 0.53380952 0.72746032\n",
            " 0.74611111        nan 0.53380952 0.53380952        nan        nan\n",
            " 0.55785714 0.53380952 0.72746032 0.72746032        nan        nan\n",
            "        nan 0.75285714 0.72746032        nan 0.75968254        nan\n",
            " 0.76365079 0.53380952        nan        nan        nan 0.72746032\n",
            " 0.64428571        nan        nan 0.53380952        nan 0.53380952\n",
            "        nan 0.72746032        nan 0.53380952 0.53380952 0.73174603\n",
            " 0.77055556        nan 0.53380952 0.53380952        nan 0.58039683\n",
            " 0.73071429        nan 0.53380952        nan        nan 0.73071429\n",
            "        nan        nan 0.6697619  0.6652381  0.6665873         nan\n",
            " 0.73071429        nan 0.73071429 0.77650794        nan 0.53380952\n",
            "        nan        nan 0.53380952 0.53380952        nan        nan\n",
            "        nan 0.73071429        nan 0.67460317 0.53380952        nan\n",
            "        nan 0.69833333        nan        nan        nan 0.53380952\n",
            " 0.73071429        nan 0.76587302 0.73071429        nan 0.53380952\n",
            "        nan 0.67611111        nan 0.77063492 0.72746032 0.75603175\n",
            "        nan        nan 0.76571429 0.73071429        nan 0.53380952\n",
            "        nan 0.70674603 0.53380952 0.73071429 0.78285714 0.61738095\n",
            "        nan 0.53380952        nan 0.73071429 0.72746032 0.72746032\n",
            " 0.73071429 0.77825397 0.73071429        nan        nan 0.53380952\n",
            " 0.76111111        nan        nan        nan 0.76738095        nan\n",
            " 0.71579365        nan        nan        nan 0.53380952 0.53380952\n",
            " 0.72746032 0.7747619         nan 0.53380952 0.53380952 0.78007937\n",
            "        nan        nan 0.53380952 0.54984127 0.72746032 0.53380952\n",
            "        nan 0.53380952 0.53380952 0.73071429        nan 0.61896825\n",
            " 0.73071429 0.53380952 0.68246032        nan 0.75761905        nan\n",
            "        nan        nan        nan        nan        nan 0.53380952\n",
            "        nan 0.53380952        nan        nan 0.77373016        nan\n",
            "        nan        nan        nan 0.75968254        nan 0.72746032\n",
            " 0.75253968 0.53380952 0.72746032        nan        nan 0.72746032\n",
            " 0.53380952 0.53380952 0.74031746 0.53380952        nan        nan\n",
            " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
            "        nan 0.53380952 0.69190476        nan 0.53380952 0.53380952\n",
            "        nan        nan 0.76539683        nan 0.53380952        nan\n",
            "        nan 0.6715873         nan        nan        nan        nan\n",
            " 0.53380952        nan        nan        nan        nan        nan\n",
            "        nan 0.72746032 0.53380952 0.53380952        nan 0.7468254\n",
            " 0.53380952 0.72746032        nan 0.72746032 0.53380952        nan\n",
            "        nan 0.72746032 0.53380952        nan        nan 0.53380952\n",
            "        nan        nan 0.76111111        nan 0.72746032        nan\n",
            "        nan 0.73071429        nan        nan        nan 0.78\n",
            " 0.72746032 0.73071429        nan        nan        nan        nan\n",
            "        nan 0.63325397 0.53380952        nan 0.53380952        nan\n",
            " 0.72746032        nan        nan 0.73230159        nan        nan\n",
            "        nan        nan 0.76555556        nan 0.72746032 0.73071429\n",
            " 0.67              nan 0.53380952        nan 0.76738095        nan\n",
            " 0.72746032        nan 0.73071429 0.77206349 0.72746032 0.73071429\n",
            " 0.78007937 0.53380952 0.72746032        nan 0.72746032        nan\n",
            " 0.53380952        nan 0.67611111        nan 0.75       0.72746032\n",
            " 0.73071429        nan        nan        nan        nan        nan\n",
            " 0.53380952 0.77531746        nan 0.61103175 0.53380952 0.72746032\n",
            "        nan        nan 0.72746032        nan 0.75753968        nan\n",
            " 0.57730159        nan 0.53380952 0.53380952 0.53380952        nan\n",
            "        nan        nan 0.72746032 0.6715873         nan 0.75325397\n",
            "        nan 0.53380952 0.53380952        nan 0.53380952        nan\n",
            "        nan        nan 0.53380952        nan        nan 0.73071429\n",
            " 0.76119048 0.72746032        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.53380952        nan 0.53380952\n",
            " 0.53380952        nan 0.73071429        nan 0.67468254 0.53380952\n",
            " 0.76214286        nan        nan 0.73071429        nan 0.70206349\n",
            "        nan 0.73071429 0.73071429 0.73071429 0.53380952 0.72746032\n",
            "        nan 0.76579365        nan 0.53380952 0.53380952        nan\n",
            " 0.73071429        nan 0.53380952        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Hyperparameters: %s' % result.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYx8pydvB7-D",
        "outputId": "43257b04-5962-47b6-9e50-b4cdea997917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 4.878363034905761, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the result is about 79% best score."
      ],
      "metadata": {
        "id": "8fgTGCvjD9TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Performing a Grid Search Optimization"
      ],
      "metadata": {
        "id": "2tyik--o7aBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
        "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
        "\n",
        "# define search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "# summarize result\n",
        "print('Best Score: %s' % result.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wftl4otJ6sj1",
        "outputId": "87b56eeb-7d1a-4d8a-9658-6d94a49d8ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7828571428571429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1440 fits failed out of a total of 2880.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.72746032 0.73071429        nan        nan        nan 0.53380952\n",
            " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.53380952\n",
            " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.53380952\n",
            " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.53380952\n",
            " 0.58039683 0.58039683 0.57246032        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.53380952\n",
            " 0.69674603 0.69674603 0.69087302        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.77857143\n",
            " 0.78285714 0.78285714 0.75444444        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.75166667\n",
            " 0.7768254  0.7768254  0.77531746        nan        nan        nan\n",
            " 0.72746032 0.73071429        nan        nan        nan 0.75166667\n",
            " 0.75492063 0.75642857 0.75325397        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Hyperparameters: %s' % result.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL0X13367wVI",
        "outputId": "dee9ad1a-b38d-4758-dc80-7ebd0bf08c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the result to be about 78% before, showing a better performance from Random Search."
      ],
      "metadata": {
        "id": "kvG7WUK4FK6k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhw-37o474o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "74W2uK6N031s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How can models be used togother?\n",
        "\n",
        "### Technical\n",
        "\n",
        "To answer the above question, we can turn to ensemble learning. Ensemble learning involves combining multiple base models to improve the overall predictive performance. We have so far assessed the effectiveness of Decision Trees, PCA, and Elastic Net in dealing with machine learning problems and pointed out a few advantages and areas where they fall short. With any model, the aim is to reduce the error rate without changing the input data to a point where the original points are unrecognizable. Combining models is one such way in which we can improve the overall outcome of the modeling process. There is vast literature that shows that ensembles or ensemble learning will yield more accurate results than single models. Models can be combined in a few ways, and we list some of them here:\n",
        "\n",
        "**Voting:**\n",
        "Voting is a straightforward ensemble method where the predictions of multiple models are combined to reach a final decision. This often involves a majority vote, where the prediction with the most votes becomes the final prediction. Alternatively, models can be assigned weights based on their performance, giving more influence to the more accurate ones. It's like a democratic process for machine learning, where each model gets a vote, and the majority's decision prevails.\n",
        "\n",
        "**Averaging:**\n",
        "Averaging is akin to voting but tailored for regression problems. Instead of choosing a single prediction, it takes the average of predictions from multiple models. This approach is particularly useful when you want to predict numerical values. You can use a simple mean or assign weights to models based on their reliability or relevance to the problem. Averaging strikes a balance among various models' opinions to provide a consolidated and often more accurate prediction.\n",
        "\n",
        "**Stacking:**\n",
        "Stacking is a more advanced ensemble method that capitalizes on the strengths of multiple models. It begins by training several base models on the data. Then, a meta-model is introduced to learn how to optimally combine the predictions of these base models. This hierarchical approach allows for a sophisticated blending of different models' insights, ultimately leading to more accurate and robust predictions.\n",
        "\n",
        "**Boosting:**\n",
        "Boosting is an iterative ensemble technique that focuses on improving the performance of weak models. It does so by assigning more weight to instances that are frequently misclassified by previous models. The final prediction is a weighted combination of these weak models, with the weights adapted during the boosting process. It's like teamwork, where each model corrects the weaknesses of its predecessors, leading to increasingly accurate predictions.\n",
        "\n",
        "**Bagging:**\n",
        "Bagging, short for Bootstrap Aggregating, involves training multiple base models independently on random subsets of the data. The final prediction is often made by averaging or using majority voting over individual model predictions. It's like conducting several mini-experiments on different parts of the dataset and then combining their results. This approach is effective at reducing the impact of outliers and variability in the data.\n",
        "\n",
        "**Random Subspace Method:**\n",
        "The Random Subspace Method is a technique designed for high-dimensional data. Here, subsets of features are randomly selected for each base model, which is then trained on these feature subsets. The final prediction combines the outputs of the individual models. This method helps to combat overfitting by reducing the complexity of each model, ensuring that no single model is overwhelmed by the dimensionality of the data.\n",
        "\n",
        "**Blending:**\n",
        "Blending is similar to stacking in that it leverages the power of multiple base models. However, it takes a different approach. Base models are trained, and then a separate dataset is used to train a meta-model. This meta-model learns how to optimally combine the base models' predictions on a validation set, which is then used to make the final prediction on the test data. Blending allows for a strategic combination of model outputs, offering a versatile approach to ensemble learning.\n",
        "\n",
        "The choice of which method to use will depend on the nature of the problem. We further make the distinction between homogeneous and heterogeneous ensemble methods. Homogeneous and heterogeneous ensemble methods refer to how similar or dissimilar the base models within an ensemble are. These terms are used to classify ensemble methods based on the diversity of the constituent models.\n",
        "In homogeneous ensemble methods, the base models are of the same type or built using the same learning algorithm. They have the same structure and make predictions using the same type of model. The diversity in these ensembles is introduced by training the base models on different subsets of the data or using different random seeds. Homogeneous ensembles tend to be simpler to implement and understand because all base models are of the same type. They are often used when the goal is to reduce overfitting, increase robustness, or improve accuracy by averaging or voting over multiple similar models. Heterogeneous ensemble methods, on the other hand, incorporate diverse types of base models. These models can be of different learning algorithms, have different structures, or use different features. The diversity introduced by using different models can lead to improved overall performance. Examples of heterogeneous ensemble methods include stacking, where different types of models are trained and then combined with a meta-model which combines different weak learners. Heterogeneous ensembles are often more complex to build and fine-tune because they involve multiple types of models.\n",
        "\n",
        "Application: What is the effect of combining models? In GWP1, we saw classification trees applied to 20 years of daily Emini S&P 500 data from Quandl, used to calculate daily returns from the \"settle price\" used as the closing price. Common technical analysis indicators for trend were used to generate trading signals. Since Quandl has data limits, we use the same dataset but using Yahoo Finance (yfinance) as the source, and the results of the model are presented below.\n"
      ],
      "metadata": {
        "id": "S6XzzZAO03ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Define the ticker symbol for E-mini S&P 500 futures (example: ES=F for the continuous front-month contract)\n",
        "ticker_symbol = \"ES=F\"\n",
        "\n",
        "# Define the start and end dates for the data you want to fetch\n",
        "start_date = \"2000-01-01\"\n",
        "end_date = \"2020-12-31\"\n",
        "\n",
        "# Use yfinance to fetch the data\n",
        "data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
        "df = pd.DataFrame(data)\n",
        "# The 'data' DataFrame now contains the E-mini S&P 500 futures data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngsgj1gj09li",
        "outputId": "8bab4709-a6be-4f80-8c36-67e185cd4ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20 years of daily Emini S&P 500 data from yfinance\n",
        "#settle price used as the closing price\n",
        "#Here we will use common technical analysis indicators for trend to generate trading signals\n",
        "# 3 indicators namely EMA, ATR, RSI and MACD\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with columns 'Settle', 'High', and 'Low'\n",
        "\n",
        "# Calculate EMA10 and EMA30\n",
        "df['EMA10'] = df['Adj Close'].rolling(window=10).mean()\n",
        "df['EMA30'] = df['Adj Close'].rolling(window=30).mean()\n",
        "\n",
        "# Calculate ATR\n",
        "df['TR'] = df['High'] - df['Low']\n",
        "df['TR'] = df[['High', 'Adj Close']].shift(1).max(axis=1) - df[['Low', 'Adj Close']].shift(1).min(axis=1)\n",
        "df['ATR'] = df['TR'].rolling(window=14).mean()\n",
        "\n",
        "\n",
        "\n",
        "# Calculate RSI\n",
        "def calculate_rsi(close, period):\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=period).mean()\n",
        "    avg_loss = loss.rolling(window=period).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "df['RSI'] = calculate_rsi(df['Adj Close'], period=14)\n",
        "\n",
        "# Calculate MACD\n",
        "short_window = 12\n",
        "long_window = 26\n",
        "signal_window = 9\n",
        "exp_short = df['Adj Close'].ewm(span=short_window, adjust=False).mean()\n",
        "exp_long = df['Adj Close'].ewm(span=long_window, adjust=False).mean()\n",
        "macd = exp_short - exp_long\n",
        "signal = macd.ewm(span=signal_window, adjust=False).mean()\n",
        "\n",
        "df['MACD'] = macd\n",
        "df['MACDsignal'] = signal\n",
        "\n",
        "df = df.drop(['TR'], axis=1)  # Drop the temporary TR column used for ATR calculation\n",
        "df.dropna(inplace=True)  # Remove rows with NaN values\n"
      ],
      "metadata": {
        "id": "eqcCgSgq1C__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#these columns will serve as predictors for the averages and the MACD\n",
        "df['ClgtEMA10'] = np.where(df['Adj Close'] > df['EMA10'], 1, -1)\n",
        "df['EMA10gtEMA30'] = np.where(df['EMA10'] > df['EMA30'], 1, -1)\n",
        "df['MACDSIGgtMACD'] = np.where(df['MACDsignal'] > df['MACD'], 1, -1)"
      ],
      "metadata": {
        "id": "nm87LuiV1G8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7bbRYT4v1CMu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5fNXQYNg1KPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# What we have now are possible trading rules that we will introduce in the\n",
        "# decision tree to help us identify the best combination of these indicators to maximize the result.\n",
        "\n",
        "# EMA, we are interested in when the price is above average and when the fastest average is above the slowest average.\n",
        "# ATR(14), we’re interested in the threshold that will trigger the signal.\n",
        "# RSI(14), we’re interested in the threshold that will trigger the signal.\n",
        "# MACD, we are interested in when the MACD signal is above MACD.\n",
        "\n",
        "df['Return'] = df['Adj Close'].pct_change(1).shift(-1)\n",
        "df['target_cls'] = np.where(df.Return > 0, 1, 0)\n",
        "# the target classificatio will be 1 if the return is positive and 0 if negetive\n"
      ],
      "metadata": {
        "id": "yeyFnHNK1Mem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "predictors_list = ['ATR','RSI', 'ClgtEMA10', 'EMA10gtEMA30', 'MACDSIGgtMACD']\n",
        "X = df[predictors_list]\n"
      ],
      "metadata": {
        "id": "XZTH2RTK1NQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we define the target classifications for each data point to use in out training\n",
        "y_cls = df.target_cls"
      ],
      "metadata": {
        "id": "UIPXmwhO1Sde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into test and trainng data\n",
        "# 80% to be used for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "y=y_cls\n",
        "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X, y, test_size=0.7, random_state=432, stratify=y)\n"
      ],
      "metadata": {
        "id": "2jrQPAXB1T8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=6)\n"
      ],
      "metadata": {
        "id": "8lqpyYPW1Wbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  we fit the model and the algorithm would already be fully trained.\n",
        "clf = clf.fit(X_cls_train, y_cls_train)\n"
      ],
      "metadata": {
        "id": "UsD_Q2Wt1YO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#usnig the model to make a forecast\n",
        "y_cls_pred = clf.predict(X_cls_test)\n"
      ],
      "metadata": {
        "id": "ld0tOMZR1a2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_cls_test, y_cls_pred)\n",
        "print (report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N0oss0V1cTN",
        "outputId": "3640e6d6-cca1-4080-d409-847ce8f7fa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.01      0.03      1638\n",
            "           1       0.54      0.98      0.70      1931\n",
            "\n",
            "    accuracy                           0.54      3569\n",
            "   macro avg       0.47      0.50      0.36      3569\n",
            "weighted avg       0.48      0.54      0.39      3569\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_SXOhKqJ1d09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the interpretation of the results is as follows:\n",
        "   - precision is based on the accuracy of the predictions i.e. the model predicts 1 (bulish signal) when the outcome is actually 1. Mathematically, precision is defined as:\n",
        "   \n",
        "<p align=\"right\">\n",
        "\\( \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Positives (FP)}} \\)\n",
        "\n",
        "          \n",
        "</p>   \n",
        "\n",
        "    - True Positives (TP): The number of positive instances correctly predicted as positive by the model.\n",
        "        \n",
        "    - False Negatives (FN): The number of positive instances incorrectly predicted as negative by the model.\n",
        "    \n",
        "    \n",
        "   \n",
        "   - The recall score is a more powere full measure of robustness. The recall score, also known as sensitivity or true positive rate, is a performance metric used in classification tasks to measure a model's ability to correctly identify all positive instances out of the total actual positive instances. It is a crucial metric, especially when dealing with imbalanced datasets or when the cost of missing positive cases is high. In essence, recall quantifies the model's ability to avoid false negatives. High recall indicates that the model is effective at capturing most of the actual positive instances, while low recall suggests that the model is missing a significant portion of the positive cases. Mathematically, recall is defined as:  \n",
        "   \n",
        " <p align=\"right\">\n",
        "  \\( \\text{Recall (Sensitivity)} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Negatives (FN)}} \\)\n",
        "</p>  \n",
        "\n",
        "  \n",
        " - F1 Score: It combines two other important metrics: precision and recall. The F1 score provides a balance between these two metrics, as it takes into account both false positives and false negatives. A higher F1 score indicates better overall model performance. The F1 score provides a harmonic mean of precision and recall, which makes it suitable for situations where you want to balance the trade-off between minimizing false positives (precision) and minimizing false negatives (recall). A higher F1 score indicates that the model achieves a better balance between precision and recall, effectively reducing both false positives and false negatives. The F1 score is calculated using the following formula:\n",
        "\n",
        " <p align=\"right\">\n",
        "          \\( \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}} \\)\n",
        " </p>\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "A model that does better than the one presented aboe would have to have a better precision as that is in escence what is we want to see we want to see a model that makes good predictions most of the time. one with better recall and precision would mean that it would perform better with out of sample data and we have seen in throughout the course how a core aim of Machine Leaning is building models that perform well with unseen data.\n",
        "\n",
        "\n",
        "To test the effect of Ensamble learning, we apply Bagging, Boosting and Stacking to the data set and compare how those models fair against each other and most importantly if they actually improve the model produced from a simple decision classification tree.   \n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "nfYwRlEc1lS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Bagging with Decision Tree\n",
        "bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='gini', max_depth=15, min_samples_leaf=16),\n",
        "                               n_estimators=100, random_state=432)\n",
        "bagging_clf.fit(X_cls_train, y_cls_train)\n",
        "bagging_preds = bagging_clf.predict(X_cls_test)\n",
        "bagging_accuracy = accuracy_score(y_cls_test, bagging_preds)\n",
        "\n",
        "# AdaBoost with Decision Tree\n",
        "adaboost_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='gini', max_depth=15, min_samples_leaf=16),\n",
        "                                 n_estimators=100, random_state=432)\n",
        "adaboost_clf.fit(X_cls_train, y_cls_train)\n",
        "adaboost_preds = adaboost_clf.predict(X_cls_test)\n",
        "adaboost_accuracy = accuracy_score(y_cls_test, adaboost_preds)\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a Stacking Classifier with Decision Tree, Bagging, and AdaBoost as base models\n",
        "base_models = [\n",
        "    ('Decision Tree', clf),\n",
        "    ('Bagging', bagging_clf),\n",
        "    ('AdaBoost', adaboost_clf)\n",
        "]\n",
        "\n",
        "# Use a logistic regression meta-estimator for stacking\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "stacking_model.fit(X_cls_train, y_cls_train)\n",
        "stacking_preds = stacking_model.predict(X_cls_test)\n",
        "\n",
        "# Calculate accuracy for the stacking model\n",
        "stacking_accuracy = accuracy_score(y_cls_test, stacking_preds)\n",
        "\n",
        "# Compare Results (include only 'recall' and 'f1-score')\n",
        "results_table = pd.DataFrame({\n",
        "    'Decision Tree': [classification_report(y_cls_test, y_cls_pred).split()[6], classification_report(y_cls_test, y_cls_pred).split()[7]],\n",
        "    'Bagging': [classification_report(y_cls_test, bagging_preds).split()[6], classification_report(y_cls_test, bagging_preds).split()[7]],\n",
        "    'AdaBoost': [classification_report(y_cls_test, adaboost_preds).split()[6], classification_report(y_cls_test, adaboost_preds).split()[7]],\n",
        "    'Stacking': [classification_report(y_cls_test, stacking_preds).split()[6], classification_report(y_cls_test, stacking_preds).split()[7]]\n",
        "}, index=['recall', 'f1-score'])\n",
        "\n",
        "print(\"Classification Report Comparison:\")\n",
        "print(results_table)\n",
        "\n",
        "\n",
        "# Calculate accuracy for the stacking model and round to 3 decimal places\n",
        "stacking_accuracy = round(accuracy_score(y_cls_test, stacking_preds), 3)\n",
        "\n",
        "# Calculate and round accuracy for other models\n",
        "decision_tree_accuracy = round(accuracy_score(y_cls_test, y_cls_pred), 3)\n",
        "bagging_accuracy = round(bagging_accuracy, 3)\n",
        "adaboost_accuracy = round(adaboost_accuracy, 3)\n",
        "\n",
        "# Print the accuracy of each model\n",
        "print(\"Accuracy of Decision Tree:\", decision_tree_accuracy)\n",
        "print(\"Accuracy of Bagging:\", bagging_accuracy)\n",
        "print(\"Accuracy of AdaBoost:\", adaboost_accuracy)\n",
        "print(\"Accuracy of Stacking:\", stacking_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMscG4tT1mBl",
        "outputId": "1f9eceea-f696-4556-8487-0277d0172b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Comparison:\n",
            "         Decision Tree Bagging AdaBoost Stacking\n",
            "recall            0.01    0.34     0.46     0.01\n",
            "f1-score          0.03    0.39     0.46     0.02\n",
            "Accuracy of Decision Tree: 0.538\n",
            "Accuracy of Bagging: 0.528\n",
            "Accuracy of AdaBoost: 0.505\n",
            "Accuracy of Stacking: 0.541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ca3lTfD1zeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The verdict is that:\n",
        "- Stacking results in a bettwe accuracy score but lowere f1 Score\n",
        "- Both bagging and boosting result in lower accuracy scores but better recall and F1-scores which means they would be better than the decision tree on out of sample data\n",
        "\n",
        "Overall ensamble learning results in technically better results and helps in improving aspects of simple models."
      ],
      "metadata": {
        "id": "O836BG7W13OG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non- Technical\n",
        "\n",
        "Ensemble learning is akin to using the collective wisdom of a group of experts, each with their unique insights and expertise. Just as we seek advice from various individuals when making significant decisions, ensemble learning combines the strengths of different machine learning models to make more accurate predictions. By doing so, ensemble methods often outperform individual models, providing a solid foundation for informed financial decision-making.\n",
        "\n",
        "Enhanced Robustness:\n",
        "\n",
        "In the dynamic world of finance, where uncertainty and market volatility are constant companions, robust predictions are paramount. Ensemble methods bolster the robustness of predictive models by mitigating the risks associated with relying on a single model. This is achieved by introducing diversity among models, which means that the potential biases and limitations of any single model are counterbalanced by the collective intelligence of the ensemble. The result is a more resilient approach to financial strategy, capable of weathering unexpected shifts in the market.\n",
        "\n",
        "Real-World Examples:\n",
        "\n",
        "The real-world impact of ensemble methods in the realm of finance is profound and far-reaching. They find applications in diverse areas, such as portfolio optimization, fraud detection, and credit scoring. In portfolio optimization, ensemble techniques help in making well-informed investment decisions by combining the forecasts of multiple models. For fraud detection, the ability to identify subtle patterns indicative of fraudulent activity is significantly enhanced. When it comes to credit scoring, ensemble models improve the accuracy of determining creditworthiness, thereby facilitating responsible lending and risk management practices. These practical examples showcase the versatility and efficacy of ensemble methods, making them invaluable tools in the financial industry. We have in the technical section demonstrated how this applies to real-world data\n",
        "\n",
        "Reduced Overfitting:\n",
        "\n",
        "Overfitting, a common pitfall in financial modeling, occurs when a model fits the training data so closely that it fails to generalize effectively to new, unseen data. Ensemble methods act as a safeguard against this issue. By amalgamating the insights of multiple models, the risk of overfitting is reduced. Each model contributes its unique perspective, and through the ensemble, the collective intelligence ensures that predictions remain accurate and reliable across various scenarios. This mitigation of overfitting is especially critical in financial decision-making, where the stakes are high and the consequences of poor predictions can be significant.\n",
        "\n",
        "Optimizing Profitability:\n",
        "\n",
        "In the finance sector, profitability is the ultimate goal. Ensemble methods play a pivotal role in achieving this objective. By improving the accuracy and stability of predictions, ensemble techniques contribute to more profitable investment strategies and enhanced risk management. The combination of diverse models, each excelling in different facets of financial analysis, results in more well-informed decisions. This, in turn, translates to better returns on investments and a reduction in the potential for financial losses. As such, ensemble methods become valuable allies in the pursuit of financial success.\n",
        "\n",
        "Overall, ensemble learning stands as a fundamental and evolving tool in the realm of financial analytics. Its power lies in the synergy it creates by amalgamating the wisdom of multiple models. The significance of ensemble methods in the financial industry is underscored by their ability to enhance robustness, mitigate overfitting, and optimize profitability.\n"
      ],
      "metadata": {
        "id": "oI0uPgH-14cO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8p4tk-e133u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}